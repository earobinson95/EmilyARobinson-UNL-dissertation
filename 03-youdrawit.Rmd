# Prediction with you draw it {#youdrawit}

```{r eyefitting-plots}

eyefitting_example_sim <- read.csv("data/youdrawit/youdrawit-eyefitting-simdata-example.csv")
eyefitting_example_simplot <- eyefitting_example_sim %>%
  filter(data == "point_data") %>%
  filter(dataset %in% c("F", "N", "S") | (x < 16 & x > 4)) %>%
  rename(`Parameter Choice` = dataset) %>%
  ggplot(aes(x = x, y = y)) +
  geom_point(size = 0.5) +
  facet_grid(~`Parameter Choice`, labeller = labeller(`Parameter Choice` = label_both)) +
  theme_bw(base_size = 14) +
  theme(aspect.ratio = 1,
        legend.position = "none",
        plot.title   = element_text(size = 8, hjust = 0),
        axis.text    = element_text(size = 6),
        axis.title   = element_text(size = 8),
        legend.title = element_text(size = 8),
        legend.text  = element_text(size = 6),
        strip.text = element_text(size = 5, margin = margin(0.05,0,0.05,0, "cm")),
        strip.background = element_rect(size = 0.5),
        legend.key.size = unit(0.5, "line")
        ) 

eyefitting_model_data <- read.csv("data/youdrawit/youdrawit-eyefitting-model-data.csv")

eyefitting.preds.lmer <- read.csv("data/youdrawit/youdrawit-eyefitting-lmerpred-data.csv")
# Plot Predictions
eyefitting.lmer.plot <- eyefitting.preds.lmer %>%
  filter((parm_id %in% c("F", "N", "S") | (x <= 16 & x >= 4))) %>%
  rename(`Parameter Choice` = parm_id) %>%
  ggplot(aes(x = x)) +
  geom_line(data = eyefitting_model_data, aes(x = x, y = residualols, group = plotID, color = "OLS"), alpha = 0.05) +
  geom_line(data = eyefitting_model_data, aes(x = x, y = residualpca, group = plotID, color = "PCA"), alpha = 0.05) +
  geom_ribbon(aes(ymin = asymp.LCL.ols, ymax = asymp.UCL.ols, fill = "OLS"), color = NA, alpha = 0.7) +
  geom_line(aes(y = emmean.ols, color = "OLS")) +
  geom_ribbon(aes(ymin = asymp.LCL.pca, ymax = asymp.UCL.pca, fill = "PCA"), color = NA, alpha = 0.7) +
  geom_line(aes(y = emmean.pca, color = "PCA")) +
  geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
  facet_grid(~`Parameter Choice`, labeller = labeller(`Parameter Choice` = label_both)) +
  theme_bw(base_size = 14) +
  theme(aspect.ratio = 1,
        legend.position = "right",
        plot.title   = element_text(size = 8, hjust = 0),
        axis.text    = element_text(size = 6),
        axis.title   = element_text(size = 8),
        legend.title = element_text(size = 8),
        legend.text  = element_text(size = 6),
        strip.text = element_text(size = 5, margin = margin(0.05,0,0.05,0, "cm")),
        strip.background = element_rect(size = 0.5),
        legend.key.size = unit(0.5, "line")
        ) +
  scale_y_continuous("Residual") +
  scale_color_manual("Estimates", values = c("steelblue", "orange")) +
  scale_fill_manual("Estimates", values = c("steelblue", "orange")) 

eyefitting.grid.gamm <- read.csv("data/youdrawit/youdrawit-eyefitting-gammpred-data.csv")
eyefitting.gamm.plot <- eyefitting.grid.gamm %>%
  filter((parm_id %in% c("F", "N", "S") | (x <= 16 & x >= 4))) %>%
  rename(`Parameter Choice` = parm_id) %>%
  ggplot(aes(x = x)) +
  geom_line(data = eyefitting_model_data, aes(x = x, y = residualols, group = plotID, color = "OLS"), alpha = 0.05) +
  geom_line(data = eyefitting_model_data, aes(x = x, y = residualpca, group = plotID, color = "PCA"), alpha = 0.05) +
  geom_ribbon(aes(ymin = ols.lower, ymax = ols.upper, fill = "OLS"), color = NA, alpha = 0.5) +
  geom_line(aes(y = ols.pred, color = "OLS")) +
  geom_ribbon(aes(ymin = pca.lower, ymax = pca.upper, fill = "PCA"), color = NA, alpha = 0.5) +
  geom_line(aes(y = pca.pred, color = "PCA")) +
  geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
  facet_grid(~`Parameter Choice`, labeller = labeller(`Parameter Choice` = label_both)) +
  theme_bw(base_size = 14) +
  theme(aspect.ratio = 1,
        legend.position = "right",
        plot.title   = element_text(size = 8, hjust = 0),
        axis.text    = element_text(size = 6),
        axis.title   = element_text(size = 8),
        legend.title = element_text(size = 8),
        legend.text  = element_text(size = 6),
        strip.text = element_text(size = 5, margin = margin(0.05,0,0.05,0, "cm")),
        strip.background = element_rect(size = 0.5),
        legend.key.size = unit(0.5, "line")
        ) +
  scale_y_continuous("Residual") +
  scale_color_manual("Estimates", values = c("steelblue", "orange")) +
  scale_fill_manual("Estimates", values = c("steelblue", "orange"))
```

## Introduction

In [Chapter 2](#lineups), a base foundation for future exploration of the use of log scales was established by evaluating participants ability to identify differences in charts through the use of lineups. 
This did not require that participants were able to understand exponential growth, identify log scales, or have any mathematical training; instead, it simply tested the change in perceptual sensitivity resulting from visualization choices. 
In order to determine whether there are cognitive disadvantages to log scales, we utilize interactive graphics to test an individual's ability to make predictions for exponentially increasing data. In this study, participants are asked to draw a line using their computer mouse through the exponentially increasing trend shown on both the log and linear scale. 

<!-- + Early studies explored the estimation and prediction of exponential growth, finding that growth is underestimated when presented both numerically and graphically but that numerical estimation is more accurate than graphical estimation for exponential curves [@wagenaar_misperception_1975].  -->

### Past Methodology

Initial studies in the 20th century explored the use of fitting lines by eye through a set of points [@finney_subjective_1951; @mosteller_eye_1981]. 
Common methods of fitting trends by eye involve maneuvering a string, black thread, or ruler until the fit is suitable, then drawing the line. 
In @finney_subjective_1951, it was of interest to determine the effect of stopping iterative maximum likelihood calculations after one iteration. Twenty-one scientists were recruited via postal mail and asked to "rule two lines" in order to judge by eye the positions for a pair of parallel probit regression lines in a biological assay.
Results indicated that one cycle of iterations was sufficient based on the starting values provided by eye from the participants.

Thirty years later, @mosteller_eye_1981, sought to understand the properties of least squares and other computed lines by establishing one systematic method of fitting lines by eye. 
The authors recruited 153 graduate students and post doctoral researchers in Introductory Biostatistics. 
Participants were asked to fit lines by eye to four sets of points using an 8.5 x 11 inch transparency with a straight line etched completely across the middle. 
A latin square design with packets of the set of points stapled together in four different orders was used in order to determine if there is an effect of order of presentation.
It was found that order of presentation had no effect and that participants tended to fit the slope of the first principal component over the slope of the least squares regression line. 

In 2015, the New York Times introduced an interactive feature, called You Draw It [@aisch_cox_quealy_2015; @buchanan_park_pearce_2017; @katz_2017]. 
Readers are asked to input their own assumptions about various metrics and learning how these asumptions relate to reality.
The NY Times team utilizes Data Driven Documents (D3) that allows readers to predict these metrics through the use of drawing a line on their computer screen with their computer mouse.

### Data Driven Documents

Major news and research organizations such as the NY Times, FiveThirtyEight, Washing Post, and the Pew Research Center create and customize graphics with Data Driven Documents. 
Data Driven Documents (D3) is an open-source JavaScript based graphing framework created by Mike Bostock during his time working on graphics at the NY Times.
For readers familiar with R, it is notable to consider D3 in JavaScript equivalent to the ggplot2 package in R. 
Similar to geometric objects and style choices in ggplot2, the grammar of D3 also includes elements such as circles, paths, and rectangles with choices of attributes and styles such as color and size.
Data Driven Documents depend on Extensible Markup Langage (XML) to generate graphics and images by binding objects and layers to the plotting area as Scalable Vector Graphics (SVG) in order to preserve the shapes rather than the pixels \pcref{fig:raster-vs-vector} \ear{CITE: https://martech.zone/vecteezy-svg-editor-online/}. 
Advantages of using D3 include animation and allowing for movement and user interaction such as hovering, clicking, and brushing. 

```{r raster-vs-vector, fig.cap = "SVG vs Raster", out.width="75%"}
knitr::include_graphics("images/raster-vs-vector.png")
```

A challenge of working with D3 is the environment necessary to display the graphics and images. 
The r2d3 package in R provides an efficient integration of D3 visuals and R by displaying them in familiar HTML output formats such as RMarkdown or Shiny applications [@r2d3].
The creator of the graphic applies D3.js code to visualize data which has previously been processed within an R setting. 

```{r r2d3-example, echo = T, eval = F}
r2d3(data = data,
     script = "d3-source-code.js",
     d3_version= "5")
```

The example R code illustrates the structure of the r2d3 function in R which includes specification of a data frame in R (converted to a JSON file), the D3.js source code file, and the D3 version that accompanies the source code.
A default SVG container for layering elements is then generated by the r2d3 function which renders the plot using the source code. 
[Appendix A](#youdrawit-with-shiny) outlines the development of the you draw it study interactive plots through the use of r2d3 with R shiny applications. 

## Study Design

This chapter first aims to establish the you draw it method as a tool for measuring predictions of trends; then this method will be used to test an individual's ability to make predictions for exponentially increasing data on both the log and linear scales, referred to as Prediction of Exponential Trends.
@mosteller_eye_1981 was replicated as part of the study data collection in order to validate the you draw it method, this will be referred to as Eye Fitting Straight Lines in the Modern Era. 
Data for both the Eye Fitting Straight Lines in the Modern Era and Prediction of Exponential Trends studies were collected in conjunction with one another over the same study participant sample. 

For each individual, a total of 6 data sets - 4 Eye Fitting Straight Lines in the Modern Era and 2 Prediction of Exponential Trends - are generated for each individual the start of the experiment. 
The 2 data sets corresponding to to the data used in the Prediction of Exponential Trends are then plotted a total of 4 times each by truncating the points at both 50% and 75% of the domain as well as on both the log and linear scales for a total of 8 task plots. 
Participants in the study are first shown 2 you draw it plot practice plots followed by 12 you draw it task plots. 
The order of all 12 task plots were randomly assigned for each individual in a completely randomized design where users saw the 4 task plots from the Eye Fitting Straight Lines in the Modern Era simulated data interspersed with the 8 task plots from the Prediction of Exponential Trends simulated data. 

## Eye Fitting Straight Lines in the Modern Era

### Data Simulation

All data processing was conducted in R before being passed to the D3.js code. 
Both studies, Eye Fitting Straight Lines in the Modern Era and Prediction of Exponential Trends, generate 30 points for $x\in [0, 20]$ based on a specific model (linear regression and exponential regression respectively) and selected coefficient and variance parameters. 
The corresponding model is then fit to the simulated points the obtain the best fit line and estimated values every 0.25 increments across the domain.
Each function then outputs a list of point data and line data both indicating the parameter identification, x value, and y value.

+ Aspect ratio = 1; yrange = range(all eye fitting data) range(1.1, 1.1)

\noindent *Algorithm: Eye Fitting Straight Lines in the Modern Era Data Generation*

**In parameters:** `y_xbar, slope, sigma, N = 30, xmin, xmax, xby = 0.25`

**Out:** data list of point data and line data

1. Randomly select and jitter N = 30 x-values along the domain.
2. Determine y-intercept at x = 0 from the provided slope and y-intercept at the mean of x (y_xbar) using point-slope form: `y - y_xbar = m(x-xbar)`
3. Generate "good" errors based on N(0,sigma). Set constraint of the mean of the first N/3 = 10 errors less than |2*sigma|
4. Simulate point data based on $y = yintercept + slope*x + error$
5. Obtain ordinary least squares regression coefficients: `lm(y ~ x, data = point_data)`
6. Simulate least squares regression line data: `y = yintercepthat + slopehat*x`
7. Output data list of point data and line data

### Parameter Selection
    
+ Parameter combinations were selected to simulate data that replicates the data sets (S, F, V, N) in [@mosteller_eye_1981]. One-way ANOVA with 4 treatments
    + **S**: positive slope, low variance (y_xbar = 3.88, slope = 0.66, sigma = 1.3, xrange = (0,20))
    + **F**: positive slope, high variance (y_xbar = 3.9, slope = 0.66, sigma = 1.98, xrange = (0,20))
    + **V**: steep positive slope (y_xbar = 3.89, slope = 1.98, sigma = 1.5, xrange = (4,18))
    + **N**: negative slope, high variance (y_xbar = 4.11, slope = -0.70, sigma = 2.5, xrange = (0,20))

### Results

To calculate the first principal component fit: https://benediktehinger.de/blog/science/scatterplots-regression-lines-and-the-first-principal-component/

1. Subset the simulated point data for a particular participant and parameter (S, F, V, N).
2. Fit a principal component over the x and y vectors from the point data (note these are the points show in the plot below). Use prcomp. Call this `pca.mod` 
3. Obtain the slope and intercept:
    + Using the pca.mod rotations we obatin the slope as: $\text{pca.slope} = \frac{\text{pca.mod rotation}[y,PC1]}{\text{pca.mod rotation}[x,PC1]}$
    + Using point-slope form we obtain the intercept as:
4. Obtain ypca values by: $y_{pca} = \text{pca.slope} \cdot x_{\text{feedback data}} + \text{pca.intercept}$

```{r eyefitting-example-plot, fig.cap = "Eye Fitting Straight Lines in the Modern Era Example", out.width="100%"}
trial.feedback <- read.csv("data/youdrawit/youdrawit-eyefitting-example-feedback.csv") %>%
    mutate(`Parameter Choice` = "F")
trial.sim <- read.csv("data/youdrawit/youdrawit-eyefitting-example-simulated.csv") %>%
    mutate(`Parameter Choice` = "F")
    
trial.feedback %>%
  ggplot(aes(x = x)) +
  geom_line(aes(y = y, color = "OLS", linetype = "OLS")) +
  geom_line(aes(y = ypca, color = "PCA", linetype = "PCA")) +
  geom_line(aes(y = ydrawn, color = "Drawn (loess)", linetype = "Drawn (loess)")) +
  geom_point(data = trial.sim, aes(y = y), size = .05) +
  facet_wrap(~`Parameter Choice`, labeller = labeller(`Parameter Choice` = label_both)) +
  theme_bw(base_size = 14) +
  theme(aspect.ratio = 1,
        legend.position = "bottom",
        axis.text    = element_text(size = 6),
        axis.title   = element_text(size = 8),
        legend.title = element_text(size = 8),
        legend.text  = element_text(size = 6),
        strip.text = element_text(size = 8, margin = margin(0.1,0,0.1,0, "cm")),
        strip.background = element_rect(size = 0.8),
        legend.key.size = unit(0.5, "line")
        ) +
  scale_x_continuous(limits = c(0,20)) +
  scale_color_manual("", values = c("steelblue", "black", "black")) +
  scale_linetype_manual("", values = c("solid", "solid", "dashed"))
```

**Treatments:**

+ parm_ID (S, F, V, N)
+ x (0, 20)

**Response:** raw residuals

+ residualols = ydrawn - yols, denoted $e_{ols}$
+ residualpca = ydrawn - ypca, denoted $e_{pca}$

**Experimental Design:**    

+ Each participant saw each of the 4 plots (new simulated data for each)

**OLS GAMM Model:**

$$y_{drawn} - y_{ols} = e_{ij,ols} = \left[\gamma_0 + \alpha_i\right] + \left[s_1(x_{ij}) + s_{2i}(x_{ij}) \right] + p_{j} + \epsilon_{ij}$$

+ $\gamma_0$ is the overall intercept
+ $\alpha_i$ is the effect of the parameter combination on the intercept (i.e. how much the intercept adjusts for each parameter combo)
+ $s_1$ is the overall spline equation for x
+ $s_{2i}$ is the adjustment to the spline equation for each parameter combination (think unequal slopes)
+ $p_{j} \sim N(0, \sigma^2_{participant})$ is the participant error due to participant variation
+ $\epsilon_{ij} \sim N(0, \sigma^2)$ is the residual error.

**PCA GAMM Model:**

$$y_{drawn} - y_{pca} = e_{ij,pca} = \left[\gamma_0 + \alpha_i\right] + \left[s_1(x_{ij}) + s_{2i}(x_{ij}) \right] + p_{j} + \epsilon_{ij}$$

+ $\gamma_0$ is the overall intercept
+ $\alpha_i$ is the effect of the parameter combination on the intercept (i.e. how much the intercept adjusts for each parameter combo)
+ $s_1$ is the overall spline equation for x
+ $s_{2i}$ is the adjustment to the spline equation for each parameter combination (think unequal slopes)
+ $p_{j} \sim N(0, \sigma^2_{participant})$ is the participant error due to participant variation
+ $\epsilon_{ij} \sim N(0, \sigma^2)$ is the residual error.

```{r eyefitting-simplot, fig.cap = "Eye Fitting Straight Lines in the Modern Era Simulated Data Example", out.width="100%"}
eyefitting_example_simplot
```

```{r eyefitting-residualplots, fig.cap = "Eye Fitting Straight Lines in the Modern Era Residual Models", out.width="100%"}
gridExtra::grid.arrange(eyefitting.lmer.plot, eyefitting.gamm.plot, ncol = 1)
```

```{r eyefitting-ss-oddsratio, fig.cap = "Eye Fitting Straight Lines in the Modern Era Sum of Squares Results", out.width="60%"}
ss.slicediffs <- read.csv("data/youdrawit/youdrawit-ssSlicediffs-lmer.csv")
ss.slicediffs %>%
  ggplot(aes(x = ratio, y = parm_id)) +
  geom_point() +
  geom_errorbar(aes(xmin = lower.CL, xmax = upper.CL), width = 0.5) +
  geom_vline(xintercept = 1, linetype = "dashed") +
  theme_bw(base_size = 14) +
  theme(aspect.ratio = 0.5,
        axis.text    = element_text(size = 6),
        axis.title   = element_text(size = 8),
        legend.title = element_text(size = 8),
        legend.text  = element_text(size = 6)
        ) +
  scale_x_continuous("Sum of Squares Odds Ratio \n (OLS vs PCA)", limits = c(0,2.5), breaks = seq(0,2.5,0.5)) +
  scale_y_discrete("Data Set")
```

## Prediction of Exponential Trends

### Data Simulation

+ aspect ratio = 1; linear = T/F; start drawing at x = 10; xrange = (0,20), yrange = range(points)*c(0.5,2)

\noindent *Algorithm 3.2: Exponential Data Generation*

**In parameters:** `beta, sd, points_choice = "partial", points_end_scale, N = 30, xmin = 0, xmax = 20, xby = 0.25`

**Out:** data list of point data and line data

1. Randomly select and jitter N = 30 x-values along the domain.
2. Generate "good" errors based on N(0,sd). Set constraint of the mean of the first N/3 = 10 errors less than |2*sd|
3. Simulate point data based on:  `y = exp(x*beta + errorVals)`
4. Obtain starting value for beta: `lm(log(y) ~ x, data = point_data)`
5. Use NLS to fit a better line to the point data: `nls(y ~ exp(x*beta), data = point_data, ...)`
6. Simulate nonlinear least squares line data: `y = exp(x*betahat)`
7. Output data list of point data and line data

### Parameter Selection

+ Visit [You Draw It Development - parameter selection](https://emily-robinson.shinyapps.io/you-draw-it-parameter-selection/) for examples.

+ Exponential (Linear/Log): 2 x 2 x 2 Factorial
    + Beta: 0.1 (sd. 0.09); 0.23 (0.25)
    + Points End: 0.5; 0.75
    + Scale: Linear; Log

### Results

+ advocate smoothing of scatterplots to assist in detecting the shape of the point cloud in situations where the error in the data is substantial, or where the density of points changes along the abscissa @cleveland_graphical_1984
+ Twitter/Reddit/Direct Email Pilot Study (05/03/2021): [Exponential Prediction](https://srvanderplas.github.io/Perception-of-Log-Scales/you-draw-it-development/you-draw-it-pilot-app/analyses/you-draw-it-exponential-prediction-pilot.html)
+ https://shiny.srvanderplas.com/you-draw-it/
+ Twitter/Reddit/Direct Email Pilot Study (05/03/2021): [Exponential Prediction](https://srvanderplas.github.io/Perception-of-Log-Scales/you-draw-it-development/you-draw-it-pilot-app/analyses/you-draw-it-exponential-prediction-pilot.html)

## Discussion and Conclusion


