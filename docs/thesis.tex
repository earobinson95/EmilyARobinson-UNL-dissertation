% From https://github.com/UWIT-IAM/UWThesis
\documentclass[print]{nuthesis}
\usepackage{amssymb, amsthm, amsmath, amsfonts}
\usepackage{wasysym}
\usepackage{mathrsfs}
% \usepackage{hyperref}
\usepackage{graphicx}
\usepackage{lineno}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{listings}
%\usepackage{breqn}
\usepackage{cancel, enumerate}
\usepackage{rotating, environ}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[inline]{enumitem}
\usepackage{dirtree}

\newtheorem{thm}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{cor}{Corollary}

% Syntax highlighting #22
  \usepackage{color}
  \usepackage{fancyvrb}
  \newcommand{\VerbBar}{|}
  \newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
  \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
  % Add ',fontsize=\small' for more characters per line
  \usepackage{framed}
  \definecolor{shadecolor}{RGB}{248,248,248}
  \newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
  \newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
  \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
  \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
  \newcommand{\BuiltInTok}[1]{#1}
  \newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
  \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
  \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
  \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
  \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
  \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
  \newcommand{\ExtensionTok}[1]{#1}
  \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
  \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
  \newcommand{\ImportTok}[1]{#1}
  \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
  \newcommand{\NormalTok}[1]{#1}
  \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
  \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
  \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
  \newcommand{\RegionMarkerTok}[1]{#1}
  \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
  \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
  \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}

%% https://github.com/rstudio/rmarkdown/issues/1649
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newenvironment{CSLReferences}[2]%
{\setlength{\parindent}{0pt}%
\everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces}%
{\par}

% fix for pandoc 1.14
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

%% something about tables, from https://github.com/ismayc/thesisdown/issues/122
\usepackage{calc}

%% for copyright symbol
\usepackage{textcomp}

%% to allow to rotate pages to landscape
\usepackage{lscape}
%% to adjust table column width
\usepackage{tabularx}

% suppress bottom page numbers on first page of each chapter
% because they overlap with text
\usepackage{etoolbox}
\patchcmd{\chapter}{plain}{empty}{}{}

%% for more attractive tables
\usepackage{booktabs}
\usepackage{longtable}


\usepackage{graphicx}


% Double spacing, if you want it.
\def\dsp{\def\baselinestretch{2.0}\large\normalsize}
% \dsp

% If the Grad. Division insists that the first paragraph of a section
% be indented (like the others), then include this line:
\usepackage{indentfirst}

%%%%%%%%%%%%%%%%%%
% If you want to use "sections" to partition your thesis
% un-comment the following:
%
% \counterwithout{section}{chapter}
% \setsecnumdepth{subsubsection}
% \def\sectionmark#1{\markboth{#1}{#1}}
% \def\subsectionmark#1{\markboth{#1}{#1}}
% \renewcommand{\thesection}{\arabic{section}}
% \renewcommand{\thesubsection}{\thesection.\arabic{subsection}}
% \makeatletter
% \let\l@subsection\l@section
% \let\l@section\l@chapter
% \makeatother
% 
% \renewcommand{\thetable}{\arabic{table}}
% \renewcommand{\thefigure}{\arabic{figure}}

%%%%%%%%%%%%%%%%%%


%% Stuff from https://github.com/suchow/Dissertate

% The following line would print the thesis in a postscript font

% \usepackage{natbib}
% \def\bibpreamble{\protect\addcontentsline{toc}{chapter}{Bibliography}}

\setcounter{tocdepth}{1} % Print the chapter and sections to the toc
% controls depth of table of contents (toc): 0 = chapter, 1 = section, 2 = subsection

\usepackage{natbib}


% commands and environments needed by pandoc snippets
% extracted from the output of `pandoc -s`
%% Make R markdown code chunks work
\usepackage{array}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifxetex
  \usepackage{fontspec,xltxtra,xunicode}
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
\else
  \ifluatex
    \usepackage{fontspec}
    \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \else
    \usepackage[utf8]{inputenc}
  \fi
\fi
\usepackage{color}
\usepackage{fancyvrb}


\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex,
              colorlinks=true,
              linkcolor=blue]{hyperref}
\else
  \usepackage[unicode=true,
              colorlinks=true,
              linkcolor=blue]{hyperref}
\fi
\hypersetup{breaklinks=true, pdfborder={0 0 0}}
\setlength{\parindent}{20pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{2} %% controls section numbering, e.g. 1 or 1.2, or 1.2.3


\input{preamble.tex}

\begin{document}
% \linenumbers{}
%% Start formatting the first few special pages
%% frontmatter is needed to set the page numbering correctly
\frontmatter
%% from thesisdown
% To pass between YAML and LaTeX the dollar signs are added by CII
\title{HUMAN PERCEPTION OF EXPONENTIALLY INCREASING DATA DISPLAYED ON A LOG SCALE EVALUATED THROUGH EXPERIMENTAL GRAPHICS TASKS}
\author{Emily Anna Robinson}
\adviser{Susan VanderPlas and Reka Howard}
\adviserAbstract{}
\major{Statistics}
\degreemonth{August}
\degreeyear{2022}
% \copyrightpage
%%
%% For most people the defaults will be correct, so they are commented
%% out. To manually set these, just uncomment and make the needed
%% changes.
%% \college{Your college}
%% \city{Your City}
%%
%% For most people the following can be changed with a class
%% option. To manually set these, just uncomment the following and
%% make the needed changes.
%% \doctype{Thesis or Dissertation}
%% \degree{Your degree}
%% \degreeabbreviation{Your degree abbr.}
%%
%% Now that we know everything we need, we can generate the title page
%% itself.
%%
\maketitle


\begin{abstract}
    Log scales are often used to display data over several orders of magnitude within one graph. Three graphical experimental tasks were conducted to evaluate the impact displaying data on the log scale has on human perception of exponentially increasing trends compared to displaying data on the linear scale. The first experiment evaluates whether our ability to perceptually notice differences in exponentially increasing trends is impacted by the choice of scale. Participants were shown a set of plots and asked to identify which plot appeared to differ most from the other plots. Results indicated that when there was a large difference in exponential curves, the choice of scale had no impact and participants accurately differentiated between the two curves on both the linear and log scale. However, displaying exponentially increasing data on a log scale improved the accuracy of differentiating between exponentially increasing curves with slight differences. An exception occurred when identifying an exponential curve from curves closely resembling a linear trend, indicating it is easy to identify a curve in a group of lines but much harder to identify a line in a group of curves. The other experimental tasks focus on determining whether there are cognitive disadvantages to log scales: do log scales make it harder to make use of graphical information? To test an individual's ability to make predictions for exponentially increasing data, participants were asked to draw a line using their computer mouse through an exponentially increasing trend shown on both the linear and log scale. Results showed that when exponential growth rate is large, underestimation of exponential growth occurs when making predictions on a linear scale and there is an improvement in accuracy of predictions made on the log scale. The last experimental task is designed to test an individuals' ability to translate a graph of exponentially increasing data into real value quantities and make comparisons of estimates. The results of the three experimental tasks provide guidelines for readers to actively choose which of many possible graphics to draw in order to ensure their charts are effective at communicating the intended result.
\end{abstract}

%% Optional
% \begin{copyrightpage}
% \end{copyrightpage}

%% Optional
% \begin{dedication}
% Dedicated to\ldots{}
% \end{dedication}

%%%%%%%%%%%%%%%%%%%
% Acknowledgments
%%%%%%%%%%%%%%%%%%%
\begin{acknowledgments}
Thank you to all my people!
\end{acknowledgments}
%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%
% Grant Information
%%%%%%%%%%%%%%%%%%%
% \begin{grantinfo}
%     % Add any grant info here
% \end{grantinfo}

%%%%%%%%%%%%%%%%%%%
% ToC
%%%%%%%%%%%%%%%%%%%
\tableofcontents

%%%%%%%%%%%%%%%%%%%
% List of Figures
%%%%%%%%%%%%%%%%%%%
\listoffigures
\listoftables

%%%%%%%%%%%%%%%%%%%
% Start of the document
%%%%%%%%%%%%%%%%%%%
\mainmatter


\hypertarget{unl-thesis-fields}{%
\chapter{UNL thesis fields}\label{unl-thesis-fields}}

Placeholder

\hypertarget{introduction-to-statistical-graphics}{%
\section{Introduction to Statistical Graphics}\label{introduction-to-statistical-graphics}}

\hypertarget{history-of-graphics}{%
\subsection{History of Graphics}\label{history-of-graphics}}

\hypertarget{misleading-graphics}{%
\subsection{Misleading Graphics}\label{misleading-graphics}}

\hypertarget{graphical-guidelines}{%
\subsection{Graphical Guidelines}\label{graphical-guidelines}}

\hypertarget{perception}{%
\section{Perception}\label{perception}}

\hypertarget{perceptual-process}{%
\subsection{Perceptual Process}\label{perceptual-process}}

\hypertarget{logarithmic-perception}{%
\subsection{Logarithmic Perception}\label{logarithmic-perception}}

\hypertarget{cognitive-tasks-and-testing-statistical-graphics}{%
\section{Cognitive Tasks and Testing Statistical Graphics}\label{cognitive-tasks-and-testing-statistical-graphics}}

\hypertarget{cognitive-fit}{%
\subsection{Cognitive Fit}\label{cognitive-fit}}

\hypertarget{testing-statistical-graphics}{%
\subsection{Testing Statistical Graphics}\label{testing-statistical-graphics}}

\hypertarget{graph-comprehension}{%
\section{Graph Comprehension}\label{graph-comprehension}}

\hypertarget{questioning}{%
\subsection{Questioning}\label{questioning}}

\hypertarget{estimation-strategies}{%
\subsection{Estimation Strategies}\label{estimation-strategies}}

\hypertarget{estimation-biases}{%
\subsection{Estimation Biases}\label{estimation-biases}}

\hypertarget{motivation-and-background}{%
\section{Motivation and Background}\label{motivation-and-background}}

\hypertarget{logarithmic-scales-and-mapping}{%
\subsection{Logarithmic Scales and Mapping}\label{logarithmic-scales-and-mapping}}

\hypertarget{underestimation}{%
\subsection{Underestimation of Exponential Growth}\label{underestimation}}

\hypertarget{research-objectives}{%
\section{Research Objectives}\label{research-objectives}}

\hypertarget{lineups}{%
\chapter{Perception through lineups}\label{lineups}}

Placeholder

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\hypertarget{visual-inference}{%
\section{Visual Inference}\label{visual-inference}}

\hypertarget{data-generation}{%
\section{Data Generation}\label{data-generation}}

\hypertarget{lineups-parameter-selection}{%
\section{Parameter Selection}\label{lineups-parameter-selection}}

\hypertarget{lineup-setup}{%
\section{Lineup Setup}\label{lineup-setup}}

\hypertarget{study-design}{%
\section{Study Design}\label{study-design}}

\hypertarget{results}{%
\section{Results}\label{results}}

\hypertarget{discussion-and-conclusion}{%
\section{Discussion and Conclusion}\label{discussion-and-conclusion}}

\hypertarget{youdrawit}{%
\chapter{Prediction with `You Draw It'}\label{youdrawit}}

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

In \protect\hyperlink{lineups}{Chapter 2}, a base foundation for future exploration of the use of log scales was established by evaluating participants ability to identify differences in charts through the use of lineups.
This did not require that participants were able to understand exponential growth, identify log scales, or have any mathematical training; instead, it simply tested whether individuals are able to perceptually distinguish different curvature and slopes in a standard scatterplot.
This is necessary, but not sufficient, to determine whether individuals are capable of higher-level interaction with statistical data on log and linear scales.
In order to determine whether there are cognitive disadvantages to log scales, we utilized interactive graphics to test an individual's ability to make predictions for exponentially increasing data.
In this study, participants were asked to draw a line using their computer mouse through an exponentially increasing trend shown on both the log and linear scales.

\hypertarget{a-review-of-regression-and-prediction}{%
\subsection{A Review of Regression and Prediction}\label{a-review-of-regression-and-prediction}}

Our visual system is naturally built to look for structure and identify patterns.
For instance, points going down from left to right indicates a negative correlation between the x and y variables.
In the past, manual methods have been used to compare our intuitive visual sense of patterns to those determined by statistical methods.
Initial studies in the 20th century explored the use of fitting lines by eye through a set of points (Finney, 1951; Mosteller, Siegel, Trapido, \& Youtz, 1981).
Common methods of fitting trends by eye involve maneuvering a string, black thread, or ruler until the fit is suitable, then drawing the line through the set of points.

Researchers in Finney (1951) were interested in assessing the effect of stopping iterative maximum likelihood calculations after one iteration.
Many techniques in statistical analysis are performed with the aid of iterative calculations such as Newton's method or Fisher's scoring.
Guesses are made at the best estimates of certain parameters and these guesses are then used as the basis of a computation which yields a new set of approximation to the parameter estimates; this same procedure is then performed on the new parameter estimates and the computing cycle is repeated until convergence, as determined by the statistician, is reached.
The author was interested in whether one iteration of calculations was sufficient in the estimation of parameters connected with dose-response relationships.
One measure of interest in dose-response relationships is the relative potency between a test preparation of doses and standard preparation of does; relative potency is calculated as the ratio of two equally effective doses between the two preparation methods.
\cref{fig:subjective-judgement} shows a pair of parallel probit responses in a biological assay.
The \(x\)-axis is the \(\log_{1.5}\) dose level for four dose levels (for example, doses 4, 6, 9, and 13 correspond correspond to equally spaced values on a logarithmic scale, labeled 0, 1, 2, and 3) and the \(y\)-axis is the corresponding probit response as calculated in Finney \& Stevens (1948); circles correspond to the test preparation method while the crosses correspond to the standard preparation method.
For these sort of assays, the does-response relationship follows a linear regression of the probit response on the logarithm of the dose levels; the two preparation methods can be constrained to be parallel (Jerne \& Wood, 1949), limiting the relative potency to one consistent value.
In this study, twenty-one scientists were recruited via postal mail and asked to ``rule two lines'' in order to judge by eye the positions for a pair of parallel probit regression lines in a biological assay \pcref{fig:subjective-judgement}.
The author then computed one iterative calculation of the relative potency based on starting values as indicated by the pair of lines provided by each participant and compared these relative potency estimates to that which was estimated by the full probit technique (reaching convergence through multiple iterations).
Results indicated that one cycle of iterations for calculating the relative potency was sufficient based on the starting values provided by eye from the participants.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"images/02{-}you{-}draw{-}it/subjective{-}judgement{-}plot.png"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.5\linewidth]{images/02-you-draw-it/subjective-judgement-plot} \caption[Subjective Judgement in Statistical Analysis (1951) Parallel Probits]{Parallel probit responses in a biological assay shown to study participants in Subjective Judgement in Statistical Analysis (1951). The $x$-axis is the $\log_{1.5}$ dose level and the $y$-axis is the corresponding probit response; circles correspond to the test preparation method while the crosses correspond to the standard preparation method.}\label{fig:subjective-judgement}
\end{figure}

Thirty years later, Mosteller et al.~(1981), sought to understand the properties of least squares and other computed lines by establishing one systematic method of fitting lines by eye.
The authors recruited 153 graduate students and post doctoral researchers in Introductory Biostatistics.
Participants were asked to fit lines by eye to four sets of points \pcref{fig:mosteller-eyefitting-plot} using an 8.5 x 11 inch transparency with a straight line etched completely across the middle.
A latin square design (Anderson \& McLean, 1974) with packets of the set of points stapled together in four different sequences was used to determine if there is an effect of order of presentation; results indicated that order of presentation had no effect.
Without a formal analysis of the study, the researchers discussed the idea that participants tended to fit the slope of the first principal component (error minimized orthogonally, both horizontal and vertical, to the regression line) over the slope of the least squares regression line (error minimized vertically to the regression line) \pcref{fig:ols-vs-pca-example}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"images/02{-}you{-}draw{-}it/eyefitting{-}straight{-}lines{-}plots.png"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.7\linewidth]{images/02-you-draw-it/eyefitting-straight-lines-plots} \caption{Eye Fitting Straight Lines (1981) Data Sets}\label{fig:mosteller-eyefitting-plot}
\end{figure}

Recently, Ciccione \& Dehaene (2021) conducted a comprehensive set of studies investigating human ability to detect trends in graphical representations from a psychophysical approach.
Participants were asked to judge trends, estimate slopes, and conduct extrapolation.
To estimate slopes, participants were asked to report the slope of the best-fitting regression line using a track-pad to adjust the tilt of a line on the screen.
Results indicated the slopes participants reported were always in excess of the ideal slopes, both in the positive and in the negative direction, and those biases increase with noise and with number of points.
This supports the results found in Mosteller et al.~(1981) and suggest that participants might use Deming regression (Deming, 1943), which is equivalent to a regression equation based ont the first principal component or principal axes and minimizes the Euclidean distance of points from the line, when fitting a line to a noisy scatter-plot.

While not explicitly intended for perceptual testing, in 2015, the New York Times introduced an interactive feature, called `You Draw It' (Aisch, Cox, \& Quealy, 2015; Buchanan, Park, \& Pearce, 2017; Katz, 2017), where readers input their own assumptions about various metrics and compare how these assumptions relate to reality.
The New York Times team utilizes Data Driven Documents (D3) that allow readers to predict these metrics through the use of drawing a line on their computer screen with their computer mouse.
\cref{fig:nyt-caraccidents} (Katz, 2017) is one such example in which readers were asked to draw the line for the missing years providing what they estimated to be the number of Americans who have died every year from car accidents, since 1990.
After the reader completed drawing the line, the actual observed values were revealed and the reader was able to check their estimated knowledge against the actual reported data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"images/02{-}you{-}draw{-}it/nyt{-}caraccidents{-}frame4.png"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.75\linewidth]{images/02-you-draw-it/nyt-caraccidents-frame4} \caption{New York Times 'You Draw It' Feature}\label{fig:nyt-caraccidents}
\end{figure}

\hypertarget{data-driven-documents}{%
\subsection{Data Driven Documents}\label{data-driven-documents}}

Major news and research organizations such as the New York Times, FiveThirtyEight, Washington Post, and the Pew Research Center create and customize graphics with Data Driven Documents (D3).
In June 2020, the New York Times released a front page displaying figures that represent each of the 100,000 lives lost from the COVID-19 pandemic until that point in time (Barry et al., 2020); this visualization was meant to bring about a visceral reaction and resonate with readers.
During 2021 March Madness, FiveThirtyEight created a roster-shuffling machine which allowed readers to build their own NBA contender through interactivity (Ryanabest, 2021).
Data Driven Documents (D3) is an open-source JavaScript based graphing framework created by Mike Bostock during his time working on graphics at the New York Times.
The grammar of D3 includes elements such as circles, paths, and rectangles with choices of attributes and styles such as color and size.
Data Driven Documents depend on Extensible Markup Language (XML) to generate graphics and images by binding objects and layers to the plotting area as Scalable Vector Graphics (SVG) in order to preserve the shapes rather than the pixels \pcref{fig:raster-vs-vector} (Tol, 2021).
Advantages of using D3 include animation and allowing for movement and user interaction such as hovering, clicking, and brushing.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"images/02{-}you{-}draw{-}it/raster{-}vs{-}vector.png"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.7\linewidth]{images/02-you-draw-it/raster-vs-vector} \caption{SVG vs Raster}\label{fig:raster-vs-vector}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# https://commons.wikimedia.org/wiki/File:Bitmap\_VS\_SVG.svg}
\CommentTok{\# https://creativecommons.org/licenses/by{-}sa/2.5/legalcode}
\end{Highlighting}
\end{Shaded}

A challenge of working with D3 is the environment necessary to display the graphics and images.
The \texttt{r2d3} package in R provides an efficient integration of D3 visuals and R by displaying them in familiar HTML output formats such as RMarkdown or Shiny applications (Luraschi \& Allaire, 2018).
The creator of the graphic applies \texttt{D3.js} source code to visualize data which has previously been processed within an R setting.

The example R code illustrates the structure of the \texttt{r2d3} function which includes specification of a data frame in R (converted to a JSON file), the D3.js source code file, and the D3 version that accompanies the source code.
A default SVG container for layering elements is then generated by the \texttt{r2d3} function which renders the plot using the source code.
\protect\hyperlink{youdrawit-with-shiny}{Appendix A} outlines the development of the `You Draw It' interactive plots used in this study through the use of \texttt{r2d3} and R shiny applications.
\cref{fig:youdrawit-example} provides an example of a `You Draw It' interactive plot as was shown to participants during the study.
The first frame shows what the participant saw along with the prompt, ``Use your mouse to fill in the trend in the yellow box region''.
Next, the yellow box region moved along as the participant drew their trend-line until the yellow region disappeared, indicating the participant had filled in the entire domain.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{r2d3}\NormalTok{(}\AttributeTok{data =}\NormalTok{ data,}
     \AttributeTok{script =} \StringTok{"d3{-}source{-}code.js"}\NormalTok{,}
     \AttributeTok{d3\_version=} \StringTok{"5"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"images/02{-}you{-}draw{-}it/ydiExample{-}0.10{-}10{-}linear.png"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=1\linewidth]{images/02-you-draw-it/ydiExample-0.10-10-linear} \caption{You Draw It Example}\label{fig:youdrawit-example}
\end{figure}

\hypertarget{study-design-1}{%
\section{Study Design}\label{study-design-1}}

This chapter contains two sub-studies; the first aims to establish `You Draw It' as a tool for measuring predictions of trends fitted by eye and a method for testing graphics, the second then applies `You Draw It' to test an individual's ability to make predictions for exponentially increasing data on the log and linear scale.
The first sub-study, referred to as Eye Fitting Straight Lines in the Modern Era, was intended to implement the `You Draw It' feature as a way to measure the patterns we see in data. We validate the `You Draw It' method for testing graphics by replicating the less technological study conducted by Mosteller et al. (1981).
Based on previous research, we hypothesize that visual regression tends to mimic principle component or Deming regression rather than an ordinary least squares regression.
In order to assess this hypothesis, we introduce a method for statistically modeling the participant drawn lines using generalized additive mixed models (GAMM).
The second sub-study, referred to as Prediction of Exponential Trends, uses the established `You Draw It' method to test an individual's ability to make predictions for exponentially increasing data on both the log and linear scales.
We then use the GAMMS to analyze participant drawn lines; a benefit of using a GAMM is the estimation of smoothing splines, allowing for flexibility in the residual trend and analysis of nonlinear trends.

A total of six data sets - four Eye Fitting Straight Lines in the Modern Era and two Prediction of Exponential Trends - are generated for each individual at the start of the experiment.
The two simulated data sets corresponding to the simulated data models used in the Prediction of Exponential Trends sub-study are then plotted a total of four times each with different aesthetic and scale choices for a total of eight task plots.
Participants in the study are first shown two `You Draw It' practice plots followed by twelve `You Draw It' task plots.
The order of all twelve task plots was randomly assigned for each individual in a completely randomized design where users saw the four task plots from the Eye Fitting Straight Lines in the Modern Era sub-study interspersed with the eight task plots from the Prediction of Exponential Trends sub-study.

The `You Draw It' study in this chapter was completed second in the series of the three graphical studies and took about fifteen minutes for participants to complete drawn trend lines for the twelve `You Draw It' task plots.
Participants completed the series of graphical tests using a R Shiny application found \href{https://shiny.srvanderplas.com/perception-of-statistical-graphics/}{here}.
Participant recruitment and study deployment was conducted via Prolific, a crowd sourcing website, on Wednesday, March 23, 2022 during which a total of 302 individuals completed 1254 unique `You Draw It' task plots for the first sub-study and 309 individuals completed 2520 unique `You Draw It' task plots associated with the second sub-study.

\hypertarget{eye-fitting-straight-lines-in-the-modern-era}{%
\section{Eye Fitting Straight Lines in the Modern Era}\label{eye-fitting-straight-lines-in-the-modern-era}}

Finney (1951) and Mosteller et al. (1981) use methods such as using a ruler, string, or transparency sheet to fit straight lines through a set of points.
This section replicates the study found in Mosteller et al. (1981) and extends this study with formal statistical analysis methods in order to establish `You Draw It' as a tool and method for testing graphics.

\hypertarget{data-generation-1}{%
\subsection{Data Generation}\label{data-generation-1}}

All data processing was conducted in R before being passed to the \texttt{D3.js} source code.
A total of \(N = 30\) points \((x_i, y_i), i = 1,...N\) were generated for \(x_i \in [x_{min}, x_{max}]\) where \(x\) and \(y\) have a linear relationship.
Data were simulated based on linear model with additive errors:
\begin{align}
y_i & = \beta_0 + \beta_1 x_i + e_i \\
\text{with } e_i & \sim N(0, \sigma^2). \nonumber
\end{align}
The parameters \(\beta_0\) and \(\beta_1\) were selected to replicate Mosteller et al. (1981) with \(e_i\) generated by rejection sampling in order to guarantee the points shown align with that of the fitted line.
An ordinary least squares regression was then fit to the simulated points in order to obtain the best fit line and fitted values in 0.25 increments across the domain, \((x_k, \hat y_{k,OLS}), k = 1, ..., 4 x_{max} +1\).
The data simulation function then outputted a list of point data and line data both indicating the parameter identification, \(x\) value, and corresponding simulated or fitted \(y\) value.
The data simulation procedure is described in \cref{alg:eyefitting-algorithm}.

\begin{algorithm}
  \caption{Eye Fitting Straight Lines in the Modern Era Data Simulation}\label{alg:eyefitting-algorithm}
  \begin{algorithmic}[1]
    \Statex \textbullet~\textbf{Input Parameters:} $y_{\bar{x}}$ for calculating the y-intercept, $\beta_0$; slope $\beta_1$; standard deviation from line $\sigma$; sample size of points $N = 30$; domain $x_{min}$ and $x_{max}$; fitted value increment $x_{by} = 0.25$.
    \Statex \textbullet~\textbf{Output Parameters:} List of point data and line data each indicating the parameter identification, $x$ value, and corresponding simulated or fitted $y$ value.
    \State Randomly select and jitter $N = 30$ $x$ values along the domain, $x_{i=1:N}\in [x_{min}, x_{max}]$.
    \State Determine the $y$-intercept, $\beta_0$, at $x = 0$ from the provided slope ($\beta_1$) and $y$ value at the mean of $x$ ($y_{\bar{x}}$) using point-slope equation of a line.
    \State Generate "good" errors, $e_{i = 1:N}$ based on $N(0,\sigma)$ by setting a constraint requiring the mean of the first $\frac{1}{3}\text{N}$ errors $< |2\sigma|.$
    \State Simulate point data based on $y_i = \beta_0 + \beta_1 x_i + e_i$
    \State Obtain ordinary least squares regression coefficients, $\hat\beta_0$ and $\hat\beta_1$, for the simulated point data using the `lm` function in the `stats` package in base R.
    \State Obtain fitted values every 0.25 increment across the domain from the ordinary least squares regression $\hat y_{k,OLS} = \hat\beta_{0,OLS} + \hat\beta_{1,OLS} x_k$.
    \State Output data list of point data and line data each indicating the parameter identification, $x$ value, and corresponding simulated or fitted $y$ value.
  \end{algorithmic}
\end{algorithm}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Parm =} \FunctionTok{c}\NormalTok{(}\StringTok{"F"}\NormalTok{, }\StringTok{"N"}\NormalTok{, }\StringTok{"S"}\NormalTok{, }\StringTok{"V"}\NormalTok{),}
           \AttributeTok{y\_xbar =} \FunctionTok{c}\NormalTok{(}\FloatTok{3.9}\NormalTok{, }\FloatTok{4.11}\NormalTok{, }\FloatTok{3.88}\NormalTok{, }\FloatTok{3.89}\NormalTok{),}
           \AttributeTok{slope =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.66}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.70}\NormalTok{, }\FloatTok{0.66}\NormalTok{, }\FloatTok{1.98}\NormalTok{),}
           \AttributeTok{sigma =} \FunctionTok{c}\NormalTok{(}\FloatTok{1.98}\NormalTok{, }\FloatTok{2.5}\NormalTok{, }\FloatTok{1.3}\NormalTok{, }\FloatTok{1.5}\NormalTok{)}
\NormalTok{           ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Parm =} \FunctionTok{factor}\NormalTok{(Parm, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"S"}\NormalTok{, }\StringTok{"F"}\NormalTok{, }\StringTok{"V"}\NormalTok{, }\StringTok{"N"}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(Parm) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}\StringTok{"latex"}\NormalTok{, }
               \AttributeTok{digits =} \DecValTok{2}\NormalTok{, }
               \AttributeTok{escape =}\NormalTok{ F, }
               \AttributeTok{booktabs =}\NormalTok{ T, }
               \AttributeTok{linesep =} \StringTok{""}\NormalTok{, }
               \AttributeTok{align =} \StringTok{"c"}\NormalTok{, }
               \AttributeTok{label =} \StringTok{"eyefitting{-}parameters"}\NormalTok{,}
               \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{"Parameter Choice"}\NormalTok{, }\StringTok{"$y\_\{}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{bar\{x\}\}$"}\NormalTok{, }\StringTok{"$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{beta\_1$"}\NormalTok{, }\StringTok{"$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{sigma$"}\NormalTok{),}
        \AttributeTok{caption =} \StringTok{"Eye Fitting Straight Lines in the Modern Era simulation model parameters"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:eyefitting-parameters}Eye Fitting Straight Lines in the Modern Era simulation model parameters}
\centering
\begin{tabular}[t]{cccc}
\toprule
Parameter Choice & $y_{\bar{x}}$ & $\beta_1$ & $\sigma$\\
\midrule
S & 3.88 & 0.66 & 1.30\\
F & 3.90 & 0.66 & 1.98\\
V & 3.89 & 1.98 & 1.50\\
N & 4.11 & -0.70 & 2.50\\
\bottomrule
\end{tabular}
\end{table}

Simulated model equation parameters were selected to reflect the four data sets (F, N, S, and V) used in Mosteller et al. (1981) \pcref{tab:eyefitting-parameters}.
Parameter choices F, N, and S simulated data across a domain of 0 to 20.
Parameter choice F produced a trend with a positive slope and a large variance while N had a negative slope and a large variance.
In comparison, S resulted a trend with a positive slope with a small variance and V yielded a steep positive slope with a small variance over the domain of 4 to 16.
\cref{fig:eyefitting-simplot} illustrates an example of simulated data for all four parameter choices intended to reflect the trends seen in \cref{fig:mosteller-eyefitting-plot}.
Aesthetic design choices were made consistent across each of the interactive `You Draw It' plots; the \(y\)-axis range extended 10\% beyond (above and below) the range of the simulated data points to allow for users to draw outside the simulated data set range and minimize participants anchoring their lines to the edges of the graph.

\begin{figure}
\includegraphics[width=1\linewidth]{thesis_files/figure-latex/eyefitting-simplot-1} \caption{Eye Fitting Straight Lines in the Modern Era Simulated Data Example}\label{fig:eyefitting-simplot}
\end{figure}

\hypertarget{results-1}{%
\subsection{Results}\label{results-1}}

In addition to the participant drawn points, \((x_k, y_{k,drawn})\), and the ordinary least squares (OLS) regression fitted values, \((x_k, \hat y_{k,OLS})\), a regression equation with a slope based on the first principal component (PCA) was used to calculate fitted values, \((x_k, \hat y_{k,PCA})\).
For each set of simulated data and parameter choice, the PCA regression slope, \(\hat\beta_{1,PCA}\), and y-intercept, \(\hat\beta_{0,PCA}\), were determined by using the \texttt{mcreg} function in the \texttt{mcr} package in R (Schuetzenmeister \& Model, 2021) which implements Deming regression (equivalent to a regression based on the slope of the first principal component).
Fitted values, \(\hat y_{k,PCA}\) were then obtained every 0.25 increment across the domain from the PCA regression equation, \(\hat y_{k,PCA} = \hat\beta_{0,PCA} + \hat\beta_{1,PCA} x_k\).
\cref{fig:ols-vs-pca-example} illustrates the difference between an OLS regression equation which minimizes the vertical distance of points from the line and a regression equation with a slope calculated by the first principal component which minimizes the smallest distance of points from the line.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(magrittr)}
\FunctionTok{library}\NormalTok{(plyr)}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\NormalTok{corrCoef }\OtherTok{=} \FloatTok{0.5} \CommentTok{\# sample from a multivariate normal, 10 datapoints}
\NormalTok{dat }\OtherTok{=}\NormalTok{ MASS}\SpecialCharTok{::}\FunctionTok{mvrnorm}\NormalTok{(}\DecValTok{10}\NormalTok{,}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{),}\AttributeTok{Sigma =} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,corrCoef,}\DecValTok{2}\NormalTok{,corrCoef),}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{dat[,}\DecValTok{1}\NormalTok{] }\OtherTok{=}\NormalTok{ dat[,}\DecValTok{1}\NormalTok{] }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(dat[,}\DecValTok{1}\NormalTok{]) }\CommentTok{\# it makes life easier for the princomp}
\NormalTok{dat[,}\DecValTok{2}\NormalTok{] }\OtherTok{=}\NormalTok{ dat[,}\DecValTok{2}\NormalTok{] }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(dat[,}\DecValTok{2}\NormalTok{])}

\NormalTok{dat }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x1 =}\NormalTok{ dat[,}\DecValTok{1}\NormalTok{],}\AttributeTok{x2 =}\NormalTok{ dat[,}\DecValTok{2}\NormalTok{])}

\CommentTok{\# Calculate the first principle component}
\CommentTok{\# see http://stats.stackexchange.com/questions/13152/how{-}to{-}perform{-}orthogonal{-}regression{-}total{-}least{-}squares{-}via{-}pca}
\NormalTok{v }\OtherTok{=}\NormalTok{ dat}\SpecialCharTok{\%\textgreater{}\%}\NormalTok{prcomp}\SpecialCharTok{\%$\%}\NormalTok{rotation}
\NormalTok{x1x2cor }\OtherTok{=}\NormalTok{ bCor }\OtherTok{=}\NormalTok{ v[}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{]}\SpecialCharTok{/}\NormalTok{v[}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{]}

\NormalTok{x1tox2 }\OtherTok{=} \FunctionTok{coef}\NormalTok{(}\FunctionTok{lm}\NormalTok{(x1}\SpecialCharTok{\textasciitilde{}}\NormalTok{x2,dat))}
\NormalTok{x2tox1 }\OtherTok{=} \FunctionTok{coef}\NormalTok{(}\FunctionTok{lm}\NormalTok{(x2}\SpecialCharTok{\textasciitilde{}}\NormalTok{x1,dat))}
\NormalTok{slopeData }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{slope =} \FunctionTok{c}\NormalTok{(x1x2cor,x2tox1[}\DecValTok{2}\NormalTok{]),}
                       \AttributeTok{type=}\FunctionTok{c}\NormalTok{(}\StringTok{"Principal Component"}\NormalTok{, }\StringTok{"Ordinary Least Squares"}\NormalTok{))}

\CommentTok{\# We want this to draw the neat orthogonal lines.}
\NormalTok{pointOnLine }\OtherTok{=} \ControlFlowTok{function}\NormalTok{(inp)\{}
  \CommentTok{\# y = a*x + c (c=0)}
  \CommentTok{\# yOrth = {-}(1/a)*x + d}
  \CommentTok{\# yOrth = b*x + d}
\NormalTok{  x0 }\OtherTok{=}\NormalTok{ inp[}\DecValTok{1}\NormalTok{] }
\NormalTok{  y0 }\OtherTok{=}\NormalTok{ inp[}\DecValTok{2}\NormalTok{] }
\NormalTok{  a }\OtherTok{=}\NormalTok{ x1x2cor}
\NormalTok{  b }\OtherTok{=} \SpecialCharTok{{-}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\NormalTok{a)}
\NormalTok{  c }\OtherTok{=} \DecValTok{0}
\NormalTok{  d }\OtherTok{=}\NormalTok{ y0 }\SpecialCharTok{{-}}\NormalTok{ b}\SpecialCharTok{*}\NormalTok{x0}
\NormalTok{  x }\OtherTok{=}\NormalTok{ (d}\SpecialCharTok{{-}}\NormalTok{c)}\SpecialCharTok{/}\NormalTok{(a}\SpecialCharTok{{-}}\NormalTok{b)}
\NormalTok{  y }\OtherTok{=} \SpecialCharTok{{-}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\NormalTok{a)}\SpecialCharTok{*}\NormalTok{x}\SpecialCharTok{+}\NormalTok{d}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{c}\NormalTok{(x,y))}
\NormalTok{\}}

\NormalTok{points }\OtherTok{=} \FunctionTok{apply}\NormalTok{(dat,}\DecValTok{1}\NormalTok{,}\AttributeTok{FUN=}\NormalTok{pointOnLine)}

\NormalTok{segmeData }\OtherTok{=} \FunctionTok{rbind}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x=}\NormalTok{dat[,}\DecValTok{1}\NormalTok{],}\AttributeTok{y=}\NormalTok{dat[,}\DecValTok{2}\NormalTok{],}\AttributeTok{xend=}\NormalTok{points[}\DecValTok{1}\NormalTok{,],}\AttributeTok{yend=}\NormalTok{points[}\DecValTok{2}\NormalTok{,],}\AttributeTok{type =} \StringTok{"Principal Component"}\NormalTok{),}
                  \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x=}\NormalTok{dat[,}\DecValTok{1}\NormalTok{],}\AttributeTok{y=}\NormalTok{dat[,}\DecValTok{2}\NormalTok{],}\AttributeTok{yend=}\NormalTok{dat[,}\DecValTok{1}\NormalTok{]}\SpecialCharTok{*}\NormalTok{x2tox1[}\DecValTok{2}\NormalTok{],}\AttributeTok{xend=}\NormalTok{dat[,}\DecValTok{1}\NormalTok{],}\AttributeTok{type=}\StringTok{"Ordinary Least Squares"}\NormalTok{))}

\NormalTok{ols\_pca\_plot }\OtherTok{\textless{}{-}}\NormalTok{ dat }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(x1,x2))}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{geom\_abline}\NormalTok{(}\AttributeTok{data=}\NormalTok{slopeData,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{slope =}\NormalTok{ slope,}\AttributeTok{intercept=}\DecValTok{0}\NormalTok{,}\AttributeTok{color=}\NormalTok{type, }\AttributeTok{linetype=}\NormalTok{type), }\AttributeTok{size =} \FloatTok{1.2}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}\AttributeTok{data=}\NormalTok{segmeData,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{x,}\AttributeTok{y=}\NormalTok{y,}\AttributeTok{xend=}\NormalTok{xend,}\AttributeTok{yend=}\NormalTok{yend,}\AttributeTok{color=}\NormalTok{type, }\AttributeTok{linetype=}\NormalTok{type))}\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(.}\SpecialCharTok{\textasciitilde{}}\NormalTok{type)}\SpecialCharTok{+}
  \FunctionTok{coord\_equal}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\StringTok{"x"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\StringTok{"y"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{(}\AttributeTok{base\_size =} \DecValTok{14}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{aspect.ratio =} \DecValTok{1}\NormalTok{,}
        \AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{,}
        \AttributeTok{axis.text    =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{12}\NormalTok{),}
        \AttributeTok{axis.title   =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{12}\NormalTok{),}
        \AttributeTok{legend.title =} \FunctionTok{element\_blank}\NormalTok{(),}
        \CommentTok{\# legend.text  = element\_text(size = 10),}
        \CommentTok{\# strip.text = element\_text(size = 8, margin = margin(0.1,0,0.1,0, "cm")),}
        \CommentTok{\# strip.background = element\_rect(size = 0.8),}
        \AttributeTok{legend.key.size =} \FunctionTok{unit}\NormalTok{(}\DecValTok{1}\NormalTok{, }\StringTok{"line"}\NormalTok{)}
\NormalTok{        ) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_manual}\NormalTok{(}\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"steelblue"}\NormalTok{, }\StringTok{"orange"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"OLS"}\NormalTok{, }\StringTok{"PCA"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_linetype\_manual}\NormalTok{(}\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"solid"}\NormalTok{, }\StringTok{"dashed"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"OLS"}\NormalTok{, }\StringTok{"PCA"}\NormalTok{))}
\NormalTok{ols\_pca\_plot}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=1\linewidth]{thesis_files/figure-latex/ols-vs-pca-example-1} \caption{OLS vs PCA Regression Lines}\label{fig:ols-vs-pca-example}
\end{figure}

For each participant, the final data set used for analysis contains \(x_{ijk}, y_{ijk,drawn}, \hat y_{ijk,OLS}\), and \(\hat y_{ijk,PCA}\) for parameter choice \(i = 1,2,3,4\), \(j = 1,...N_{participant}\), and \(x_{ijk}\) value \(k = 1, ...,4 x_{max} + 1\).
Using both a linear mixed model (LMM) and a generalized additive mixed model (GAMM), comparisons of vertical residuals in relation to the OLS fitted values (\(e_{ijk,OLS} = y_{ijk,drawn} - \hat y_{ijk,OLS}\)) and PCA fitted values (\(e_{ijk,PCA} = y_{ijk,drawn} - \hat y_{ijk,PCA}\)) were made across the domain.
\cref{fig:eyefitting-example-plot} displays an example of all three fitted trend lines for parameter choice F.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{eyefitting\_example }\OtherTok{\textless{}{-}}\NormalTok{ eyefitting\_model\_data }\SpecialCharTok{\%\textgreater{}\%}
  \CommentTok{\# filter(participant\_id == "65c10d498eae365e108efcd3dcb75287", parm\_id == "N") \%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(participant\_id }\SpecialCharTok{==} \StringTok{"60b16b9bd5a122c1457d31055df51a45"}\NormalTok{, }\StringTok{\textasciigrave{}}\AttributeTok{Parameter Choice}\StringTok{\textasciigrave{}} \SpecialCharTok{==} \StringTok{"F"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ yols, }\AttributeTok{color =} \StringTok{"OLS"}\NormalTok{, }\AttributeTok{linetype =} \StringTok{"OLS"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ ypca, }\AttributeTok{color =} \StringTok{"PCA"}\NormalTok{, }\AttributeTok{linetype =} \StringTok{"PCA"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ ydrawn, }\AttributeTok{color =} \StringTok{"Drawn"}\NormalTok{, }\AttributeTok{linetype =} \StringTok{"Drawn"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data =}\NormalTok{ eyefitting\_simulated\_data }\SpecialCharTok{\%\textgreater{}\%}
               \FunctionTok{filter}\NormalTok{(dataset }\SpecialCharTok{==} \StringTok{"point\_data"}\NormalTok{, participant\_id }\SpecialCharTok{==} \StringTok{"60b16b9bd5a122c1457d31055df51a45"}\NormalTok{, }\StringTok{\textasciigrave{}}\AttributeTok{Parameter Choice}\StringTok{\textasciigrave{}} \SpecialCharTok{==} \StringTok{"F"}\NormalTok{),}
             \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\StringTok{\textasciigrave{}}\AttributeTok{Parameter Choice}\StringTok{\textasciigrave{}}\NormalTok{, }\AttributeTok{labeller =} \FunctionTok{labeller}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{Parameter Choice}\StringTok{\textasciigrave{}} \OtherTok{=}\NormalTok{ label\_both)) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{(}\AttributeTok{base\_size =} \DecValTok{14}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{aspect.ratio =} \DecValTok{1}\NormalTok{,}
        \AttributeTok{legend.position =} \StringTok{"bottom"}\NormalTok{,}
        \AttributeTok{axis.text    =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{12}\NormalTok{),}
        \AttributeTok{axis.title   =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{12}\NormalTok{),}
        \AttributeTok{legend.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{12}\NormalTok{),}
        \AttributeTok{legend.text  =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{12}\NormalTok{),}
        \CommentTok{\# strip.text = element\_text(size = 8, margin = margin(0.1,0,0.1,0, "cm")),}
        \CommentTok{\# strip.background = element\_rect(size = 0.8),}
        \AttributeTok{legend.key.size =} \FunctionTok{unit}\NormalTok{(}\DecValTok{1}\NormalTok{, }\StringTok{"line"}\NormalTok{)}
\NormalTok{        ) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{limits =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{20}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_manual}\NormalTok{(}\StringTok{""}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"steelblue"}\NormalTok{, }\StringTok{"orange"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_linetype\_manual}\NormalTok{(}\StringTok{""}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"dashed"}\NormalTok{, }\StringTok{"solid"}\NormalTok{, }\StringTok{"solid"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\StringTok{"y"}\NormalTok{)}

\NormalTok{eyefitting\_example}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=1\linewidth]{thesis_files/figure-latex/eyefitting-example-plot-1} \caption{Eye Fitting Straight Lines in the Modern Era Example}\label{fig:eyefitting-example-plot}
\end{figure}

Using the \texttt{lmer} function in the \texttt{lme4} package (Bates, Mchler, Bolker, \& Walker, 2015), a LMM is fit separately to the OLS and PCA residuals, constraining the fit to a linear trend.
Parameter choice, \(x\), and the interaction between \(x\) and parameter choice were treated as fixed effects with a random participant effect accounting for variation due to participant.
The LMM equation for each fit (OLS and PCA) residuals is given by:
\begin{equation}
y_{ijk,drawn} - \hat y_{ijk,fit} = e_{ijk,fit} = \left[\gamma_0 + \alpha_i\right] + \left[\gamma_{1} x_{ijk} + \gamma_{2i} x_{ijk}\right] + p_{j} + \epsilon_{ijk}
\end{equation}
\noindent where

\begin{itemize}
\tightlist
\item
  \(y_{ijk,drawn}\) is the drawn y-value for the \(i^{th}\) parameter choice, \(j^{th}\) participant, and \(k^{th}\) increment of x-value
\item
  \(\hat y_{ijk,fit}\) is the fitted y-value for the \(i^{th}\) parameter choice, \(j^{th}\) participant, and \(k^{th}\) increment of x-value corresponding to either the OLS or PCA fit
\item
  \(e_{ijk,fit}\) is the residual between the drawn and fitted y-values for the \(i^{th}\) parameter choice, \(j^{th}\) participant, and \(k^{th}\) increment of x-value corresponding to either the OLS or PCA fit
\item
  \(\gamma_0\) is the overall intercept
\item
  \(\alpha_i\) is the effect of the \(i^{th}\) parameter choice (F, S, V, N) on the intercept
\item
  \(\gamma_1\) is the overall slope for \(x\)
\item
  \(\gamma_{2i}\) is the effect of the parameter choice on the slope
\item
  \(x_{ijk}\) is the x-value for the \(i^{th}\) parameter choice, \(j^{th}\) participant, and \(k^{th}\) increment
\item
  \(p_{j} \sim N(0, \sigma^2_{participant})\) is the random error due to the \(j^{th}\) participant's characteristics
\item
  \(\epsilon_{ijk} \sim N(0, \sigma^2)\) is the residual error.
\end{itemize}

Eliminating the linear trend constraint, the \texttt{bam} function in the \texttt{mgcv} package (Wood, 2003, 2004, 2011, 2017; Wood, Pya, \& Sfken, 2016) is used to fit a GAMM separately to the OLS and PCA residuals to allow for estimation of smoothing splines.
Parameter choice was treated as a fixed effect with no estimated intercept and a separate smoothing spline for \(x\) was estimated for each parameter choice.
A random participant effect accounting for variation due to participant and a random spline for each participant accounted for variation in spline for each participant.
The GAMM equation for each fit (OLS and PCA) residuals is given by:
\begin{equation}
y_{ijk, drawn} - \hat y_{ijk, fit} = e_{ijk,fit} = \alpha_i + s_{i}(x_{ijk}) + p_{j} + s_{j}(x_{ijk})
\end{equation}
\noindent where

\begin{itemize}
\tightlist
\item
  \(y_{ijk,drawn}\) is the drawn y-value for the \(i^{th}\) parameter choice, \(j^{th}\) participant, and \(k^{th}\) increment of x-value
\item
  \(\hat y_{ijk,fit}\) is the fitted y-value for the \(i^{th}\) parameter choice, \(j^{th}\) participant, and \(k^{th}\) increment of x-value corresponding to either the OLS or PCA fit
\item
  \(e_{ijk,fit}\) is the residual between the drawn and fitted y-values for the \(i^{th}\) parameter choice, \(j^{th}\) participant, and \(k^{th}\) increment of x-value corresponding to either the OLS or PCA fit
\item
  \(\alpha_i\) is the intercept for the parameter choice \(i\)
\item
  \(s_{i}\) is the smoothing spline for the \(i^{th}\) parameter choice
\item
  \(x_{ijk}\) is the x-value for the \(i^{th}\) parameter choice, \(j^{th}\) participant, and \(k^{th}\) increment
\item
  \(p_{j} \sim N(0, \sigma^2_{participant})\) is the error due to participant variation
\item
  \(s_{j}\) is the random smoothing spline for each participant.
\end{itemize}

\cref{fig:eyefitting-lmer-residualplots} and \cref{fig:eyefitting-gamm-residualplots} show the estimated trends of residuals (vertical deviation of participant drawn points from both the OLS and PCA fitted points) as modeled by a LMM and GAMM respectively.
A random sample of 75 participants was selected to display individual participant residuals behind the overall residual trend.
Examining the plots, the estimated trends of PCA residuals (orange) appear to align more parallel and closer to the \(y=0\) horizontal (dashed) line than the OLS residuals (blue).
In particular, this trend is more prominent in parameter choices with large variances (F and N).
These results are consistent to those found in Mosteller et al. (1981) indicating participants fit a trend line closer to the estimated regression line with the slope of the first principal component than the estimated OLS regression line.
This study established `You Draw It' as a method for graphical testing and reinforced the differences between intuitive visual model fitting and statistical model fitting, providing information about human perception as it relates to the use of statistical graphics.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{68505}\NormalTok{)}
\NormalTok{participant\_sample }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{unique}\NormalTok{(eyefitting\_model\_data}\SpecialCharTok{$}\NormalTok{prolific\_id), }\DecValTok{75}\NormalTok{)}

\CommentTok{\# Plot Predictions}
\NormalTok{eyefitting\_lmer\_plot }\OtherTok{\textless{}{-}}\NormalTok{ eyefitting\_lmer\_preds }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{((}\StringTok{\textasciigrave{}}\AttributeTok{Parameter Choice}\StringTok{\textasciigrave{}} \SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"F"}\NormalTok{, }\StringTok{"N"}\NormalTok{, }\StringTok{"S"}\NormalTok{) }\SpecialCharTok{|}\NormalTok{ (x }\SpecialCharTok{\textless{}=} \DecValTok{16} \SpecialCharTok{\&}\NormalTok{ x }\SpecialCharTok{\textgreater{}=} \DecValTok{4}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{Parameter Choice}\StringTok{\textasciigrave{}} \OtherTok{=} \FunctionTok{factor}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{Parameter Choice}\StringTok{\textasciigrave{}}\NormalTok{, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"S"}\NormalTok{, }\StringTok{"F"}\NormalTok{, }\StringTok{"V"}\NormalTok{, }\StringTok{"N"}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =}\NormalTok{ eyefitting\_model\_data }\SpecialCharTok{\%\textgreater{}\%} 
              \FunctionTok{filter}\NormalTok{(prolific\_id }\SpecialCharTok{\%in\%}\NormalTok{ participant\_sample), }
            \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ residual\_ols\_loess, }\AttributeTok{group =}\NormalTok{ plot\_id, }\AttributeTok{color =} \StringTok{"OLS"}\NormalTok{), }\AttributeTok{alpha =} \FloatTok{0.1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =}\NormalTok{ eyefitting\_model\_data }\SpecialCharTok{\%\textgreater{}\%} 
              \FunctionTok{filter}\NormalTok{(prolific\_id }\SpecialCharTok{\%in\%}\NormalTok{ participant\_sample), }
            \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ residual\_pca\_loess, }\AttributeTok{group =}\NormalTok{ plot\_id, }\AttributeTok{color =} \StringTok{"PCA"}\NormalTok{), }\AttributeTok{alpha =} \FloatTok{0.1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_ribbon}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ asymp.LCL.ols, }\AttributeTok{ymax =}\NormalTok{ asymp.UCL.ols, }\AttributeTok{fill =} \StringTok{"OLS"}\NormalTok{), }\AttributeTok{color =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.4}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ emmean.ols, }\AttributeTok{color =} \StringTok{"OLS"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{geom\_ribbon}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ asymp.LCL.pca, }\AttributeTok{ymax =}\NormalTok{ asymp.UCL.pca, }\AttributeTok{fill =} \StringTok{"PCA"}\NormalTok{), }\AttributeTok{color =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.4}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ emmean.pca, }\AttributeTok{color =} \StringTok{"PCA"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\StringTok{\textasciigrave{}}\AttributeTok{Parameter Choice}\StringTok{\textasciigrave{}}\NormalTok{, }\AttributeTok{labeller =} \FunctionTok{labeller}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{Parameter Choice}\StringTok{\textasciigrave{}} \OtherTok{=}\NormalTok{ label\_both), }\AttributeTok{scales =} \StringTok{"free"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{(}\AttributeTok{base\_size =} \DecValTok{14}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{aspect.ratio =} \DecValTok{1}\NormalTok{,}
        \AttributeTok{legend.position =} \StringTok{"right"}\NormalTok{,}
        \AttributeTok{plot.title   =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{12}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{0}\NormalTok{),}
        \AttributeTok{axis.text    =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{12}\NormalTok{),}
        \AttributeTok{axis.title   =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{12}\NormalTok{),}
        \AttributeTok{legend.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{12}\NormalTok{),}
        \AttributeTok{legend.text  =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{12}\NormalTok{),}
        \CommentTok{\# strip.text = element\_text(size = 5, margin = margin(0.05,0,0.05,0, "cm")),}
        \CommentTok{\# strip.background = element\_rect(size = 0.5),}
        \AttributeTok{legend.key.size =} \FunctionTok{unit}\NormalTok{(}\DecValTok{1}\NormalTok{, }\StringTok{"line"}\NormalTok{)}
\NormalTok{        ) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\StringTok{"Residual"}\NormalTok{, }\AttributeTok{limits =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{,}\DecValTok{5}\NormalTok{), }\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{,}\DecValTok{5}\NormalTok{,}\FloatTok{2.5}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_manual}\NormalTok{(}\StringTok{"Individual participant }\SpecialCharTok{\textbackslash{}n}\StringTok{residuals"}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"steelblue"}\NormalTok{, }\StringTok{"orange"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"OLS"}\NormalTok{, }\StringTok{"PCA"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_manual}\NormalTok{(}\StringTok{"LMER fitted trend"}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"steelblue"}\NormalTok{, }\StringTok{"orange"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"OLS"}\NormalTok{, }\StringTok{"PCA"}\NormalTok{))  }\SpecialCharTok{+}
  \FunctionTok{guides}\NormalTok{(}\AttributeTok{color =} \FunctionTok{guide\_legend}\NormalTok{(}\AttributeTok{override.aes =} \FunctionTok{list}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{1}\NormalTok{)),}
         \AttributeTok{fill =} \FunctionTok{guide\_legend}\NormalTok{(}\AttributeTok{override.aes =} \FunctionTok{list}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{1}\NormalTok{)))}

\NormalTok{eyefitting\_lmer\_plot}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=1\linewidth]{thesis_files/figure-latex/eyefitting-lmer-residualplots-1} \caption{Eye Fitting Straight Lines in the Modern Era LMM results}\label{fig:eyefitting-lmer-residualplots}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{eyefitting\_gamm\_plot }\OtherTok{\textless{}{-}}\NormalTok{ eyefitting\_gamm\_preds }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{((}\StringTok{\textasciigrave{}}\AttributeTok{Parameter Choice}\StringTok{\textasciigrave{}} \SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"F"}\NormalTok{, }\StringTok{"N"}\NormalTok{, }\StringTok{"S"}\NormalTok{) }\SpecialCharTok{|}\NormalTok{ (x }\SpecialCharTok{\textless{}=} \DecValTok{16} \SpecialCharTok{\&}\NormalTok{ x }\SpecialCharTok{\textgreater{}=} \DecValTok{4}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{Parameter Choice}\StringTok{\textasciigrave{}} \OtherTok{=} \FunctionTok{factor}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{Parameter Choice}\StringTok{\textasciigrave{}}\NormalTok{, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"S"}\NormalTok{, }\StringTok{"F"}\NormalTok{, }\StringTok{"V"}\NormalTok{, }\StringTok{"N"}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =}\NormalTok{ eyefitting\_model\_data }\SpecialCharTok{\%\textgreater{}\%} 
              \FunctionTok{filter}\NormalTok{(prolific\_id }\SpecialCharTok{\%in\%}\NormalTok{ participant\_sample), }
            \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ residual\_ols\_loess, }\AttributeTok{group =}\NormalTok{ plot\_id, }\AttributeTok{color =} \StringTok{"OLS"}\NormalTok{), }\AttributeTok{alpha =} \FloatTok{0.1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =}\NormalTok{ eyefitting\_model\_data }\SpecialCharTok{\%\textgreater{}\%} 
              \FunctionTok{filter}\NormalTok{(prolific\_id }\SpecialCharTok{\%in\%}\NormalTok{ participant\_sample), }
            \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ residual\_pca\_loess, }\AttributeTok{group =}\NormalTok{ plot\_id, }\AttributeTok{color =} \StringTok{"PCA"}\NormalTok{), }\AttributeTok{alpha =} \FloatTok{0.1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_ribbon}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ ols.lower, }\AttributeTok{ymax =}\NormalTok{ ols.upper, }\AttributeTok{fill =} \StringTok{"OLS"}\NormalTok{), }\AttributeTok{color =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.4}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ ols.pred, }\AttributeTok{color =} \StringTok{"OLS"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{geom\_ribbon}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ pca.lower, }\AttributeTok{ymax =}\NormalTok{ pca.upper, }\AttributeTok{fill =} \StringTok{"PCA"}\NormalTok{), }\AttributeTok{color =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.4}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ pca.pred, }\AttributeTok{color =} \StringTok{"PCA"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\StringTok{\textasciigrave{}}\AttributeTok{Parameter Choice}\StringTok{\textasciigrave{}}\NormalTok{, }\AttributeTok{labeller =} \FunctionTok{labeller}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{Parameter Choice}\StringTok{\textasciigrave{}} \OtherTok{=}\NormalTok{ label\_both), }\AttributeTok{scales =} \StringTok{"free"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{(}\AttributeTok{base\_size =} \DecValTok{14}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{aspect.ratio =} \DecValTok{1}\NormalTok{,}
        \AttributeTok{legend.position =} \StringTok{"right"}\NormalTok{,}
        \AttributeTok{plot.title   =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{12}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{0}\NormalTok{),}
        \AttributeTok{axis.text    =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{12}\NormalTok{),}
        \AttributeTok{axis.title   =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{12}\NormalTok{),}
        \AttributeTok{legend.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{12}\NormalTok{),}
        \AttributeTok{legend.text  =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{12}\NormalTok{),}
        \CommentTok{\# strip.text = element\_text(size = 5, margin = margin(0.05,0,0.05,0, "cm")),}
        \CommentTok{\# strip.background = element\_rect(size = 0.5),}
        \AttributeTok{legend.key.size =} \FunctionTok{unit}\NormalTok{(}\DecValTok{1}\NormalTok{, }\StringTok{"line"}\NormalTok{)}
\NormalTok{        ) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\StringTok{"Residual"}\NormalTok{, }\AttributeTok{limits =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{,}\DecValTok{5}\NormalTok{), }\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{,}\DecValTok{5}\NormalTok{,}\FloatTok{2.5}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_manual}\NormalTok{(}\StringTok{"Individual participant }\SpecialCharTok{\textbackslash{}n}\StringTok{residuals"}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"steelblue"}\NormalTok{, }\StringTok{"orange"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"OLS"}\NormalTok{, }\StringTok{"PCA"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_manual}\NormalTok{(}\StringTok{"GAMM fitted trend"}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"steelblue"}\NormalTok{, }\StringTok{"orange"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"OLS"}\NormalTok{, }\StringTok{"PCA"}\NormalTok{))   }\SpecialCharTok{+}
  \FunctionTok{guides}\NormalTok{(}\AttributeTok{color =} \FunctionTok{guide\_legend}\NormalTok{(}\AttributeTok{override.aes =} \FunctionTok{list}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{1}\NormalTok{)),}
         \AttributeTok{fill =} \FunctionTok{guide\_legend}\NormalTok{(}\AttributeTok{override.aes =} \FunctionTok{list}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{1}\NormalTok{)))}

\NormalTok{eyefitting\_gamm\_plot}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=1\linewidth]{thesis_files/figure-latex/eyefitting-gamm-residualplots-1} \caption{Eye Fitting Straight Lines in the Modern Era GAMM results}\label{fig:eyefitting-gamm-residualplots}
\end{figure}

\hypertarget{prediction-of-exponential-trends}{%
\section{Prediction of Exponential Trends}\label{prediction-of-exponential-trends}}

The results from the first sub-study validated `You Draw It' as a tool for testing graphics.
This sub-study was designed to test an individual's ability to make predictions for exponentially increasing data on both the log and linear scales, addressing cognitive understanding of log scales.
Participants were asked to draw a line using their computer mouse through the exponentially increasing trend shown on both the log and linear scale.

\hypertarget{data-generation-2}{%
\subsection{Data Generation}\label{data-generation-2}}

All data processing was conducted in R before being passed to the D3.js source code.
A total of \(N = 30\) points \((x_i, y_i), i = 1,...N\) were generated for \(x_i\in [x_{min}, x_{max}]\) where \(x\) and \(y\) have an exponential relationship.
Data were simulated based on a one parameter exponential model with multiplicative errors:
\begin{align}
y_i & = e^{\beta x_i + e_i} \\
\text{with } e_i & \sim N(0, \sigma^2). \nonumber
\end{align}
The parameter, \(\beta\), was selected to reflect the rate of exponential growth with \(e_i\) generated by rejection sampling in order to guarantee the points shown align with that of the fitted line displayed in the initial plot frame.
A nonlinear least squares regression is then fit to the simulated points in order to obtain the best fit line and fitted values in 0.25 increments across the domain, \((x_m, \hat y_{m,NLS}), k = 1, ..., 4 x_{max} +1\).
The data simulation function then outputs a list of point data and line data both indicating the parameter identification, \(x\) value, and corresponding simulated or fitted \(y\) value.
The data simulation procedure is described in \cref{alg:exponential-prediction-alg}.

\begin{algorithm}
  \caption{Prediction of Exponential Trends Data Simulation}\label{alg:exponential-prediction-alg}
  \begin{algorithmic}[1]
    \Statex \textbullet~\textbf{Input Parameters:} $\beta$ growth rate; standard deviation from exponential curve $\sigma$; sample size of points $N = 30$; domain $x_{min}$ and $x_{max}$; fitted value increment $x_{by} = 0.25$.
    \Statex \textbullet~\textbf{Output Parameters:} List of point data and line data each indicating the parameter identification, $x$ value, and corresponding simulated or fitted $y$ value.
    \State Randomly select and jitter $N = 30$ $x$-values along the domain, $x_{i=1:N}\in [0, 20]$.
    \State Generate "good" errors, $e_{i = 1:N}$ based on $N(0,\sigma)$ by setting a constraint requiring the mean of the first $\frac{1}{3} N$ errors $< |2\sigma|.$
    \State Simulate point data based on $y_i = e^{\beta x_i + e_i}$.
    \State Fit the equation $\log(y_i) = \beta x_i$ to obtain an estimated starting value $\beta_0$. 
    \State Obtain nonlinear least squares regression coefficient, $\hat\beta_{NLS}$, for the simulated point data fitting using the `nls` function in the base `stats` R package.
    \State Obtain fitted values every 0.25 increment across the domain from the nonlinear least squares regression $\hat y_{m,NLS} = e^{\hat\beta_{NLS} x_m}$.
    \State Output data list of point data and line data each indicating the parameter identification, $x$ value, and corresponding simulated or fitted $y$ value.
  \end{algorithmic}
\end{algorithm}

Model equation parameter, \(\beta\), was selected to reflect two exponential growth rates (low: \(\beta = 0.10, \sigma = 0.09\) and high: \(\beta = 0.23, \sigma = 0.25\)) as determined by visual inspection with growth rate parameter selection from the lineup study in \protect\hyperlink{lineups-parameter-selection}{Chapter 2} used as a starting point.
Each growth rate parameter was used to simulate data across a domain of 0 to 20.
The two simulated data sets (low and high exponential growth rates) were then shown four times each by truncating the points shown at both 50\% and 75\% of the domain as well as on both the log and linear scales for a total of eight interactive plots reflecting a factorial treatment design.
\protect\hyperlink{exponential-prediction-plots}{Appendix B} displays visual examples of all eight interactive plots.
Aesthetic design choices were made consistent across each of the interactive `You Draw It' plots; the \(y\)-axis extended 50\% below the lower limit of the simulated data range and 200\% beyond the upper limit of the simulated data range to allow for users to draw outside the data set range, and participants were asked to start drawing at 50\% of the domain (for example, at \(x = 10\)).
Reflecting the treatment design for each plot, the y-axis was assigned to be displayed on either the linear scale or log scale.

\hypertarget{results-2}{%
\subsection{Results}\label{results-2}}

A LOESS smoother (local regression) was fit to each user line to allow for visual inspection.
For each participant \(l = 1,...N_{participant}\), the final data set used for analysis contained \(x_{ijklm}, y_{ijklm,drawn}, \hat y_{ijklm,loess}\), and \(\hat y_{ijklm,NLS}\) for growth rate \(i = 1,2\), points truncated \(j = 1,2\), scale \(k = 1,2\) and \(x_{ijklm}\) value for increment \(m = 1, ...,81\).
\cref{fig:exponential-yloess-spaghetti-plot} displays spaghetti plots for each of the eight treatment combinations.
The spaghetti plot with a high growth rate suggests participants underestimated the exponential trend when asked to draw a trend line on the linear scale compared to when asked to draw a trend line on the log scale.
In particular, this suggestion is most noticeable when points are truncated at 50\% with the underestimation beginning at a later \(x\) value when points are truncated at 75\%.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spaghetti\_plot }\OtherTok{\textless{}{-}}\NormalTok{ youdrawit\_model\_data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ yloess, }\AttributeTok{group =}\NormalTok{ plot\_id, }\AttributeTok{color =}\NormalTok{ scale), }\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_ribbon}\NormalTok{(}\AttributeTok{data =}\NormalTok{ youdrawit\_simulated\_band, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ min\_ynls, }\AttributeTok{ymax =}\NormalTok{ max\_ynls, }\AttributeTok{fill =} \StringTok{"Fitted NLS"}\NormalTok{, }\AttributeTok{group =} \ConstantTok{NA}\NormalTok{), }\AttributeTok{color =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.35}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{Growth Rate}\StringTok{\textasciigrave{}} \SpecialCharTok{\textasciitilde{}} \StringTok{\textasciigrave{}}\AttributeTok{Points Truncated}\StringTok{\textasciigrave{}}\NormalTok{, }\AttributeTok{scales =} \StringTok{"free"}\NormalTok{, }\AttributeTok{labeller =} \FunctionTok{labeller}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{Growth Rate}\StringTok{\textasciigrave{}} \OtherTok{=}\NormalTok{ label\_both, }\StringTok{\textasciigrave{}}\AttributeTok{Points Truncated}\StringTok{\textasciigrave{}} \OtherTok{=}\NormalTok{ label\_both)) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{aspect.ratio =} \DecValTok{1}\NormalTok{,}
        \AttributeTok{legend.position =} \StringTok{"bottom"}
\NormalTok{        ) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_manual}\NormalTok{(}\StringTok{""}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"steelblue"}\NormalTok{, }\StringTok{"orange"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Linear Scale }\SpecialCharTok{\textbackslash{}n}\StringTok{ (drawn, loess)"}\NormalTok{, }\StringTok{"Log Scale }\SpecialCharTok{\textbackslash{}n}\StringTok{ (drawn, loess)"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_manual}\NormalTok{(}\StringTok{""}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Fitted Band }\SpecialCharTok{\textbackslash{}n}\StringTok{ (NLS)"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{limits =} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\StringTok{"y"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{guides}\NormalTok{(}\AttributeTok{color =} \FunctionTok{guide\_legend}\NormalTok{(}\AttributeTok{override.aes =} \FunctionTok{list}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{1}\NormalTok{)),}
         \AttributeTok{fill =} \FunctionTok{guide\_legend}\NormalTok{(}\AttributeTok{override.aes =} \FunctionTok{list}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{)))}
\NormalTok{spaghetti\_plot}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=1\linewidth]{thesis_files/figure-latex/exponential-yloess-spaghetti-plot-1} \caption{Exponential Prediction Spaghetti Plot}\label{fig:exponential-yloess-spaghetti-plot}
\end{figure}

Allowing for flexibility, the \texttt{bam} function in the \texttt{mgcv} package (Wood, 2003, 2004, 2011, 2017; Wood et al., 2016) was used to fit a GAMM to estimate trends of vertical residuals from the participant drawn line in relation to the NLS fitted values (\(e_{ijklm,NLS} = y_{ijklm,drawn} - \hat y_{ijklm,NLS}\)) across the domain.
The combination between growth rate, point truncation, and scale was treated as a fixed effect with no estimated intercept and a separate smoothing spline for \(x\) was estimated for each treatment combination.
A random participant effect accounting for variation due to participant and a random spline for each participant accounted for variation in spline for each participant.
The GAMM equation for residuals is given by:
\begin{equation}
y_{ijklm,drawn} - \hat y_{ijklm,NLS} = e_{ijklm,nls} = \tau_{ijk} + s_{ijk}(x_{ijklm}) + p_{l} + s_{l}(x_{ijklm})
\end{equation}
\noindent where

\begin{itemize}
\tightlist
\item
  \(y_{ijklm,drawn}\) is the drawn y-value for the \(l^{th}\) participant, \(m^{th}\) increment, and \(ijk^{th}\) treatment combination
\item
  \(\hat y_{ijklm,NLS}\) is the NLS fitted y-value for the \(l^{th}\) participant, \(m^{th}\) increment, and \(ijk^{th}\) treatment combination
\item
  \(e_{ijklm,NLS}\) is the residual between the drawn y-value and fitted y-value for the \(l^{th}\) participant, \(m^{th}\) increment, and \(ijk^{th}\) treatment combination
\item
  \(\tau_{ijk}\) is the intercept for the \(i^{th}\) growth rate, \(j^{th}\) point truncation, and \(k^{th}\) scale treatment combination
\item
  \(s_{ijk}\) is the smoothing spline for the \(ijk^{th}\) treatment combination
\item
  \(x_{ijklm}\) is the x-value for the \(l^{th}\) participant, \(m^{th}\) increment, and \(ijk^{th}\) treatment combination
\item
  \(p_{l} \sim N(0, \sigma^2_{participant})\) is the error due to the \(l^{th}\) participant's characteristics
\item
  \(s_{l}\) is the random smoothing spline for the \(l^{th}\) participant.
\end{itemize}

\cref{fig:exponential-prediction-gamm-preds} shows the estimated trends of the residuals (vertical deviation of participant drawn points from NLS fitted points) as modeled by the GAMM.
Examining the plots, the estimated trends of residuals for predictions made on the linear scale (blue) appear to deviate from the \(y=0\) horizontal (dashed) line indicating underestimation of exponential growth.
In comparisons, the estimated trends of residuals for predictions made on the log scale (orange) follow closely to the \(y=0\) horizontal (dashed) line, implying exponential trends predicted on the log scale are more accurate than those predicted on the linear scale.
In particular, this trend is more prominent in high exponential growth rates where underestimation becomes prominent after the aid of points is removed.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{68505}\NormalTok{)}
\NormalTok{participant\_sample2 }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{unique}\NormalTok{(youdrawit\_model\_data}\SpecialCharTok{$}\NormalTok{prolific\_id), }\DecValTok{75}\NormalTok{)}

\NormalTok{gamm\_plot\_0}\FloatTok{.1} \OtherTok{\textless{}{-}}\NormalTok{ youdrawit\_preds\_gamm\_0}\FloatTok{.1} \SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ estimate, }\AttributeTok{group =}\NormalTok{ scale, }\AttributeTok{color =}\NormalTok{ scale, }\AttributeTok{fill =}\NormalTok{ scale)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =}\NormalTok{ youdrawit\_model\_data }\SpecialCharTok{\%\textgreater{}\%} 
              \FunctionTok{filter}\NormalTok{(beta }\SpecialCharTok{==} \StringTok{"beta0.1"}\NormalTok{, prolific\_id }\SpecialCharTok{\%in\%}\NormalTok{ participant\_sample2), }
            \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ residual\_nls\_drawn, }\AttributeTok{group =}\NormalTok{ plot\_id), }\AttributeTok{alpha =} \FloatTok{0.1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_ribbon}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ lower, }\AttributeTok{ymax =}\NormalTok{ upper), }\AttributeTok{color =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.4}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{Growth Rate}\StringTok{\textasciigrave{}} \SpecialCharTok{\textasciitilde{}} \StringTok{\textasciigrave{}}\AttributeTok{Points Truncated}\StringTok{\textasciigrave{}}\NormalTok{, }\AttributeTok{scales =} \StringTok{"free"}\NormalTok{, }\AttributeTok{labeller =} \FunctionTok{labeller}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{Growth Rate}\StringTok{\textasciigrave{}} \OtherTok{=}\NormalTok{ label\_both, }\StringTok{\textasciigrave{}}\AttributeTok{Points Truncated}\StringTok{\textasciigrave{}} \OtherTok{=}\NormalTok{ label\_both)) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{aspect.ratio =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\StringTok{"Residual }\SpecialCharTok{\textbackslash{}n}\StringTok{ (ydrawn {-} ynls)"}\NormalTok{, }\AttributeTok{limits =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{8}\NormalTok{, }\DecValTok{8}\NormalTok{), }\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{10}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_manual}\NormalTok{(}\StringTok{"Individual participant }\SpecialCharTok{\textbackslash{}n}\StringTok{residuals"}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"steelblue"}\NormalTok{, }\StringTok{"orange2"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Linear scale"}\NormalTok{, }\StringTok{"Log scale"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_manual}\NormalTok{(}\StringTok{"GAMM fitted trend"}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"steelblue"}\NormalTok{, }\StringTok{"orange2"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Linear scale"}\NormalTok{, }\StringTok{"Log scale"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{guides}\NormalTok{(}\AttributeTok{color =} \FunctionTok{guide\_legend}\NormalTok{(}\AttributeTok{override.aes =} \FunctionTok{list}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{1}\NormalTok{)),}
         \AttributeTok{fill =} \FunctionTok{guide\_legend}\NormalTok{(}\AttributeTok{override.aes =} \FunctionTok{list}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{1}\NormalTok{)))}

\NormalTok{gamm\_plot\_0}\FloatTok{.23} \OtherTok{\textless{}{-}}\NormalTok{ youdrawit\_preds\_gamm\_0}\FloatTok{.23} \SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ estimate, }\AttributeTok{group =}\NormalTok{ scale, }\AttributeTok{color =}\NormalTok{ scale, }\AttributeTok{fill =}\NormalTok{ scale)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =}\NormalTok{ youdrawit\_model\_data }\SpecialCharTok{\%\textgreater{}\%} 
              \FunctionTok{filter}\NormalTok{(beta }\SpecialCharTok{==} \StringTok{"beta0.23"}\NormalTok{, prolific\_id }\SpecialCharTok{\%in\%}\NormalTok{ participant\_sample2), }
            \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ residual\_nls\_drawn, }\AttributeTok{group =}\NormalTok{ plot\_id), }\AttributeTok{alpha =} \FloatTok{0.1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_ribbon}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ lower, }\AttributeTok{ymax =}\NormalTok{ upper), }\AttributeTok{color =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.4}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{Growth Rate}\StringTok{\textasciigrave{}} \SpecialCharTok{\textasciitilde{}} \StringTok{\textasciigrave{}}\AttributeTok{Points Truncated}\StringTok{\textasciigrave{}}\NormalTok{, }\AttributeTok{scales =} \StringTok{"free"}\NormalTok{, }\AttributeTok{labeller =} \FunctionTok{labeller}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{Growth Rate}\StringTok{\textasciigrave{}} \OtherTok{=}\NormalTok{ label\_both, }\StringTok{\textasciigrave{}}\AttributeTok{Points Truncated}\StringTok{\textasciigrave{}} \OtherTok{=}\NormalTok{ label\_both)) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{aspect.ratio =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\StringTok{"Residual }\SpecialCharTok{\textbackslash{}n}\StringTok{ (ydrawn {-} ynls)"}\NormalTok{, }\AttributeTok{limits =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{150}\NormalTok{, }\DecValTok{225}\NormalTok{), }\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{200}\NormalTok{,}\DecValTok{200}\NormalTok{,}\DecValTok{50}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_manual}\NormalTok{(}\StringTok{"Individual participant }\SpecialCharTok{\textbackslash{}n}\StringTok{residuals"}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"steelblue"}\NormalTok{, }\StringTok{"orange2"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Linear scale"}\NormalTok{, }\StringTok{"Log scale"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_manual}\NormalTok{(}\StringTok{"GAMM fitted trend"}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"steelblue"}\NormalTok{, }\StringTok{"orange2"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Linear scale"}\NormalTok{, }\StringTok{"Log scale"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{guides}\NormalTok{(}\AttributeTok{color =} \FunctionTok{guide\_legend}\NormalTok{(}\AttributeTok{override.aes =} \FunctionTok{list}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{1}\NormalTok{)),}
         \AttributeTok{fill =} \FunctionTok{guide\_legend}\NormalTok{(}\AttributeTok{override.aes =} \FunctionTok{list}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{1}\NormalTok{)))}

\NormalTok{gamm\_plot\_0}\FloatTok{.1}\SpecialCharTok{/}
\NormalTok{gamm\_plot\_0}\FloatTok{.23}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=1\linewidth]{thesis_files/figure-latex/exponential-prediction-gamm-preds-1} \caption{Exponential Prediction GAMM Results}\label{fig:exponential-prediction-gamm-preds}
\end{figure}

\hypertarget{discussion-and-conclusion-1}{%
\section{Discussion and Conclusion}\label{discussion-and-conclusion-1}}

The intent of this chapter was to establish `You Draw It' as a method and tool for testing graphics then use this tool to determine the cognitive implications of displaying data on the log scale.
Eye Fitting Straight Lines in the Modern Era replicated the results found in Mosteller et al. (1981).
When shown points following a linear trend, participants tended to fit the slope of the first principal component over the slope of the least squares regression line.
This trend was most prominent when shown data simulated with larger variances.
The reproducibility of these results serve as evidence of the reliability of the `You Draw It' method.

In Prediction of Exponential Trends, the `You Draw It' method was used to test an individual's ability to make predictions for exponentially increasing data.
Results indicate that underestimation of exponential growth occurs when participants were asked to draw trend lines on the linear scale and that there was an improvement in accuracy when trends were drawn on the log scale.
This phenomena is strongly supported for high exponential growth rates.
Improvement in predictions are made when points along the exponential trend are shown as indicated by the discrepancy in results for treatments with points truncated at 50\% compared to 75\% of the domain.

The results of this study suggest that there are cognitive advantages to log scales when making predictions of exponential trends.
Participants' predictions were more accurate at high growth rates when participants drew trend lines on the log scale compared to the linear scale.
Further investigation is necessary to determine the implications of using log scales when translating exponential graphs to numerical values; we address this problem in the next chapter.

\hypertarget{estimation}{%
\chapter{Numerical Translation and Estimation}\label{estimation}}

Placeholder

\hypertarget{introduction-2}{%
\section{Introduction}\label{introduction-2}}

\hypertarget{graph-comprehension-1}{%
\subsection{Graph Comprehension}\label{graph-comprehension-1}}

\hypertarget{estimation-biases-1}{%
\subsection{Estimation Biases}\label{estimation-biases-1}}

\hypertarget{study-design-2}{%
\section{Study Design}\label{study-design-2}}

\hypertarget{data-generation-3}{%
\section{Data Generation}\label{data-generation-3}}

\hypertarget{results-3}{%
\section{Results}\label{results-3}}

\hypertarget{open-ended}{%
\subsection{Open Ended}\label{open-ended}}

\hypertarget{elementary-q1-estimation-of-population}{%
\subsection{Elementary Q1: Estimation of population}\label{elementary-q1-estimation-of-population}}

\hypertarget{elementary-q2-estimation-of-time}{%
\subsection{Elementary Q2: Estimation of time}\label{elementary-q2-estimation-of-time}}

\hypertarget{intermediate-q1-additive-increase-in-population}{%
\subsection{Intermediate Q1: Additive increase in population}\label{intermediate-q1-additive-increase-in-population}}

\hypertarget{intermediate-q2-multiplicative-change-in-population}{%
\subsection{Intermediate Q2: Multiplicative change in population}\label{intermediate-q2-multiplicative-change-in-population}}

\hypertarget{intermediate-q3-time-until-population-doubles}{%
\subsection{Intermediate Q3: Time until population doubles}\label{intermediate-q3-time-until-population-doubles}}

\hypertarget{discussion-and-conclusion-2}{%
\section{Discussion and Conclusion}\label{discussion-and-conclusion-2}}

\hypertarget{conclusion}{%
\chapter{Conclusion}\label{conclusion}}

Placeholder

\hypertarget{youdrawit-with-shiny}{%
\chapter{You Draw It Setup with Shiny}\label{youdrawit-with-shiny}}

Placeholder

\hypertarget{estimation-comparison}{%
\section{Scratchwork participant comparison}\label{estimation-comparison}}

\hypertarget{references}{%
\chapter*{References}\label{references}}
\addcontentsline{toc}{chapter}{References}

Placeholder

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-aisch_cox_quealy_2015}{}}%
Aisch, G., Cox, A., \& Quealy, K. (2015, May). You draw it: How family income predicts children's college chances. \emph{The New York Times}. The New York Times. Retrieved from \url{https://www.nytimes.com/interactive/2015/05/28/upshot/you-draw-it-how-family-income-affects-childrens-college-chances.html}

\leavevmode\vadjust pre{\hypertarget{ref-anderson_design_1974}{}}%
Anderson, V. L., \& McLean, R. A. (1974). \emph{Design of experiments: A realistic approach}. New York: M. Dekker.

\leavevmode\vadjust pre{\hypertarget{ref-NYTrememberinglives}{}}%
Barry, D., Buchanan, L., Cargill, C., Daniel, A., Delaqurire, A., Gamio, L., \ldots{} al., et. (2020, May). Remembering the 100,000 lives lost to coronavirus in america. \emph{The New York Times}. The New York Times. Retrieved from \url{https://www.nytimes.com/interactive/2020/05/24/us/us-coronavirus-deaths-100000.html}

\leavevmode\vadjust pre{\hypertarget{ref-lme4}{}}%
Bates, D., Mchler, M., Bolker, B., \& Walker, S. (2015). Fitting linear mixed-effects models using {lme4}. \emph{Journal of Statistical Software}, \emph{67}(1), 1--48. http://doi.org/\href{https://doi.org/10.18637/jss.v067.i01}{10.18637/jss.v067.i01}

\leavevmode\vadjust pre{\hypertarget{ref-buchanan_park_pearce_2017}{}}%
Buchanan, L., Park, H., \& Pearce, A. (2017, January). You draw it: What got better or worse during obama's presidency. \emph{The New York Times}. The New York Times. Retrieved from \url{https://www.nytimes.com/interactive/2017/01/15/us/politics/you-draw-obama-legacy.html}

\leavevmode\vadjust pre{\hypertarget{ref-ciccione2021can}{}}%
Ciccione, L., \& Dehaene, S. (2021). Can humans perform mental regression on a graph? Accuracy and bias in the perception of scatterplots. \emph{Cognitive Psychology}, \emph{128}, 101406.

\leavevmode\vadjust pre{\hypertarget{ref-deming1943statistical}{}}%
Deming, W. E. (1943). Statistical adjustment of data.

\leavevmode\vadjust pre{\hypertarget{ref-finney_subjective_1951}{}}%
Finney, D. (1951). Subjective judgment in statistical analysis: An experimental study. \emph{Journal of the Royal Statistical Society: Series B (Methodological)}, \emph{13}(2), 284--297.

\leavevmode\vadjust pre{\hypertarget{ref-finney1948table}{}}%
Finney, D., \& Stevens, W. (1948). A table for the calculation of working probits and weights in probit analysis. \emph{Biometrika}, \emph{35}(1/2), 191--201.

\leavevmode\vadjust pre{\hypertarget{ref-jerne1949validity}{}}%
Jerne, N. K., \& Wood, E. C. (1949). The validity and meaning of the results of biological assays. \emph{Biometrics}, \emph{5}(4), 273--299.

\leavevmode\vadjust pre{\hypertarget{ref-katz_2017}{}}%
Katz, J. (2017, April). You draw it: Just how bad is the drug overdose epidemic? \emph{The New York Times}. The New York Times. Retrieved from \url{https://www.nytimes.com/interactive/2017/04/14/upshot/drug-overdose-epidemic-you-draw-it.html}

\leavevmode\vadjust pre{\hypertarget{ref-r2d3}{}}%
Luraschi, J., \& Allaire, J. (2018). \emph{r2d3: Interface to 'D3' visualizations}. Retrieved from \url{https://CRAN.R-project.org/package=r2d3}

\leavevmode\vadjust pre{\hypertarget{ref-mosteller_eye_1981}{}}%
Mosteller, F., Siegel, A. F., Trapido, E., \& Youtz, C. (1981). Eye fitting straight lines. \emph{The American Statistician}, \emph{35}(3), 150--152.

\leavevmode\vadjust pre{\hypertarget{ref-ryanabest_2021}{}}%
Ryanabest. (2021, June). Build an NBA contender with our roster-shuffling machine. \emph{FiveThirtyEight}. Retrieved from \url{https://projects.fivethirtyeight.com/nba-trades-2021/}

\leavevmode\vadjust pre{\hypertarget{ref-mcr_pkg}{}}%
Schuetzenmeister, A., \& Model, F. (2021). \emph{Mcr: Method comparison regression}. Retrieved from \url{https://CRAN.R-project.org/package=mcr}

\leavevmode\vadjust pre{\hypertarget{ref-raster_vs_svg}{}}%
Tol. (2021). Bitmap VS SVG. Retrieved from \url{https://commons.wikimedia.org/wiki/File:Bitmap_VS_SVG.svg}

\leavevmode\vadjust pre{\hypertarget{ref-mgcv5}{}}%
Wood, S. (2003). Thin plate regression splines. \emph{Journal of the Royal Statistical Society: Series B (Statistical Methodology)}, \emph{65}(1), 95--114.

\leavevmode\vadjust pre{\hypertarget{ref-mgcv3}{}}%
Wood, S. (2004). Stable and efficient multiple smoothing parameter estimation for generalized additive models. \emph{Journal of the American Statistical Association}, \emph{99}(467), 673--686.

\leavevmode\vadjust pre{\hypertarget{ref-mgcv1}{}}%
Wood, S. (2011). Fast stable restricted maximum likelihood and marginal likelihood estimation of semiparametric generalized linear models. \emph{Journal of the Royal Statistical Society: Series B (Statistical Methodology)}, \emph{73}(1), 3--36.

\leavevmode\vadjust pre{\hypertarget{ref-mgcv4}{}}%
Wood, S. (2017). \emph{Generalized additive models: An introduction with r} (2nd ed.). Chapman; Hall/CRC.

\leavevmode\vadjust pre{\hypertarget{ref-mgcv2}{}}%
Wood, S., Pya, N., \& Sfken, B. (2016). Smoothing parameter and model selection for general smooth models. \emph{Journal of the American Statistical Association}, \emph{111}(516), 1548--1563.

\end{CSLReferences}


%% backmatter is needed at the end of the main body of your thesis to
%% set up page numbering correctly for the remainder of the thesis
\backmatter

%% Start the correct formatting for the appendices
% \appendix
%% Input each appendix here
% \input{./appendix_a}

%% Bibliography goes here (You better have one)
%% BibTeX is your friend

% \bibliographystyle{alpha}  % or use  abbrv to abbreviate first names and use numerical indices
\bibliographystyle{abbrv}  % or use  abbrv to abbreviate first names and use numerical indices
%% Add your BibTex file here (don't include the .bib)
\bibliography{./references}



%% Index go here (if you have one)
\end{document}
