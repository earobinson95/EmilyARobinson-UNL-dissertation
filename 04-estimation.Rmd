# Numerical Translation and Estimation {#estimation}

```{r estimation-setup, message=FALSE, warning=FALSE, echo = F}
library(tidyverse)
library(patchwork)
library(ggforce)
library(ggpubr)
library(here)
library(readr)
library(knitr)
library(kableExtra)
# library(pander)

library(ggwordcloud)
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(tm) 
library(tidytext)
library(corpus)
library(reshape2)
```

```{r estimation-data, message=FALSE, warning=FALSE, echo = F}
estimation_model_data <- read.csv(here("data/03-estimation/estimation-model-data.csv"))
q0_text_summary <- read.csv(here("data/03-estimation/q0-text-summary.csv"))
estimation_simulated_data <- read.csv(here("data/03-estimation/estimation-simulated-data.csv")) %>%
  mutate(x = x - 3000)
estimation_scenario_text <- read.csv(here("data/03-estimation/estimation-scenario-text.csv"))
estimation_parameters <- read.csv(here("data/03-estimation/estimation-parameters.csv"))
estimation_questions <- read.csv(here("data/03-estimation/estimation-questions.csv"))
population_estimates_data <- read.csv(here("data/03-estimation/first-level-population-estimates.csv"))

grid_lines_data <- tibble(scale = c(rep("linear", 12), rep("log2", 10)), 
                          grid_lines = c(seq(0,55000, 5000),
                                         2^seq(7,16))
) %>%
  expand_grid(dataset = c("dataset1", "dataset2"))
```

```{r density-plot}
densityPlot <- function(data, datasetID, estimate, xlabel = "Estimate", x_limits = c(0,70000), zoom = F, zoom_limits = c(NA,NA), gridlines = T){
  
  estPlot <- data %>%
    filter(dataset %in% datasetID) %>%
    ggplot(aes_string(x = estimate, fill = "scale", color = "scale")) +
    geom_density(alpha = 0.5, color = NA) +
    geom_rug(alpha = 0.8, show.legend = F) +
    geom_vline(aes(xintercept = true_value, linetype = "a")) +
    geom_vline(aes(xintercept = closest_pt_value, linetype = "b"))
  
  if(gridlines){
  estPlot <- estPlot + 
    geom_vline(data = grid_lines_data %>% filter(dataset == "dataset1", grid_lines >= x_limits[1], grid_lines <= x_limits[2]),
               aes(xintercept = grid_lines, color = scale, linetype = "c"))
  }
  
  estPlot <- estPlot +
    theme_bw() +
    theme(aspect.ratio = 0.5) +
    scale_color_manual("Scale", values = c("steelblue", "orange3")) +
    scale_fill_manual("Scale", values = c("steelblue", "orange3")) +
    scale_linetype_manual("", labels = c("True Value", "Closest Point Value", "Grid Line Breaks"), values = c("solid", "dashed", "dotted")) +
    scale_y_continuous("Density")
  
  if(zoom){
  estPlot <- estPlot +
    facet_zoom(xlim = zoom_limits) +
    scale_x_continuous(xlabel)
  }
  
  if(!zoom){
    estPlot <- estPlot +
    scale_x_continuous(xlabel, limits = x_limits)
  }
    
  return(estPlot)
  
}
```

## Introduction

The previous two chapters explored the use of log scales through differentiation and visual prediction of trends. 
These graphical tasks were conducted independent of scenarios or contextual applications of logarithmic scales; instead, they focused how our visual system perceives and identifies patterns in exponential growth.
In order to understand the cognitive implications of displaying exponentially increasing data on a log scale, it is essential to evaluate graph comprehension as it relates to the contextual scenario of the data shown.
This is a complex inferential process which requires participants to engage with the data by quantitatively transforming information in the chart [@cleveland_graphical_1984; @cleveland_graphical_1985].
In this study, I ask participants to translate a graph of exponentially increasing data into real value quantities and extend their estimations by comparing two data points.

<!-- Such complex inferential processes involve quantitatively transforming the information in the display (e.g., mentally transforming from a linear to logarithmic scale or calculating the difference between two or more data points; Cleveland, 1984, 1985). -->

### Graph Comprehension

Graph comprehension is heavily dependent on the questions being asked of the viewer; therefore, questioning is an important aspect of comprehension and must be given deliberate consideration [@graesser2014new]. 
Evaluation of how viewers explore a new and complex graphic requires long-term interaction with the chart displaying the data [@becker2019trackr]. 
While it is difficult to obtain an accurate representation of a viewers understanding of the graphic with a fixed set of numerical estimates, three levels of graph comprehension have emerged from literature [@wood1968objectives; @curcio1987comprehension; @jolliffe1991assessment; @friel2001making; @glazer2011challenges].
The three behaviors related to graph comprehension involve (1) literal reading of the data (elementary level), (2) reading between the data (intermediate level), and (3) reading beyond the data (advanced level).

<!-- Comprehension of information in written or symbolic form involves three kinds of behaviors (Jolliffe, 1991; Wood, 1968) that seem to be related to graph comprehension: (1) translation, (2) interpretation, and (3) extrapolation/interpolation. -->

### Rounding Estimates & Anchoring

+ Open-ended estimation tasks elicit certain well-known biases such as the tendency to round to multiples of 5 or 10 [@becker2019trackr]

## Study Design

Participants in this study were asked to answer six questions related to each of two contextual scenarios and an associated scatter plot shown for a total of twelve questions. 
The text for each scenario is presented below; the context of both scenarios was selected to be similar.
Each text describes a situation in which a fictional intergalactic species is exponentially increasing in population over a time measure adjusted to reflect the popular culture media depiction of that species [@star_wars1; @star_wars2; @star_trek]. For simplicity, I will refer to this fictional time component as a year throughout.

\begin{quote}
\textbf{\textit{Tribble scenario.}} Hi, we're Tribbles! We were taken from our native planet, Iota Germinorum IV, and brought abroad Starfleet in stardate 4500. A Starfleet scientist, Edward Larkin, genetically engineered us to increase our reproductive rate in an attempt to solve a planetary food shortage. The Tribble population on Starfleet over the next 50 Stardates (equivalent to 1 week universe time) is illustrated in the graph. We need your help answering a few questions regarding the population of Tribbles.

\textbf{\textit{Ewok scenario.}} Hi, we're Ewoks! We are native to the forest moon of Endor. After the Galactic Civil War, some Ewoks traveled offworld to help Rebel veterans as 'therapy Ewoks' and began to repopulate. The Ewok population After the Battle of Yavin (ABY) is illustrated in the graph. We need your help answering a few questions regarding the population of Ewoks offworld.
\end{quote}

Fictional illustrations of the figures used in context were modified from artwork by @allison_horst and included on the main page for each scenario.
The scale of the graphic and data set displayed was randomly assigned to scenarios for each individual. 
For instance, a participant may have seen a scatter plot of data set two displayed on the linear scale paired with the Ewok scenario text and a scatter plot of data set one displayed on the log scale paired with the Tribble scenario text.
The order of the two scenarios and their assigned data set and scale was randomly assigned to each individual.

I selected the six questions \pcref{tab:estimation-questions-table} for graph comprehension based on the three defined levels of questioning.
In each scenario, participants were first asked an open ended question, which required them to spend time exploring the data displayed in the graphic, followed by a random order of two elementary level questions and three intermediate level questions.
I did not focus on advanced level questioning since extrapolation and interpolation was addressed in [Chapter 2](#youdrawit).

```{r, estimation-questions-table, echo = F}
estimation_questions %>%
  filter(q_id != "scenario") %>%
  pivot_wider(id_cols = "q_id",
              names_from = "creature",
              values_from = "qtext") %>%
  mutate(q_id = c("Open Ended", "Elementary Q1", "Elementary Q2", "Intermediate Q1", "Intermediate Q2", "Intermediate Q3")) %>%
  kableExtra::kable("latex", booktabs = T, col.names = c("Question type", "Tribble scenario", "Ewok scenario"),
               caption = "Estimation Questions")  %>%
  kableExtra::column_spec(2:3, width = "10em")
```

The estimation study in this chapter was completed last in the series of the three graphical studies and took about fifteen minutes for participants to answer all twelve estimation questions.
Participants completed the series of graphical tests using a R Shiny application found [here](https://shiny.srvanderplas.com/perception-of-statistical-graphics/). 
For each of the quantitative translation questions, participants were provided a basic calculator and scratchpad to aid in their estimation of values.
I recorded the inputted and evaluated calculations and scratch work of each participant in order to understand participant strategies for estimation.

## Data Generation

I generated two unique data sets with the same underlying parameter coefficients, but different errors randomly generated from the same error distribution. For each data set, a total of $N = 50$ points $(x_i, y_i), i = 1,...N$ were generated for single increments of $x_i\in [0, 50]$ where $x$ and $y$ have an exponential relationship.
Data were simulated based on a three parameter exponential model with multiplicative errors: 
\begin{align}
y_i & = \alpha e^{\beta x_i + e_i} + \theta \\
\text{with } e_i & \sim N(0, \sigma^2). \nonumber
\end{align} 
The underlying parameter coefficients were selected to follow a similar growth rate and shape as the previous two studies by visual inspection while ensuring in a maximum magnitude of around 50,000.
The resulting parameters selected for data generation were $\alpha = 130$, $\beta = 0.12$, $\theta = 50$, and $\sigma = 1.5$.

```{r estimation-simulated-data, fig.cap = "Estimation simulated data", fig.height=9, fig.width=9, echo = F, message=FALSE, warning=FALSE, out.width="100%", echo = F}

# dataset 1
simulated_plot_linear1 <- estimation_simulated_data %>%
  filter(dataset == "dataset1") %>%
  mutate(scale = "Linear") %>%
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  geom_line(aes(y = y0), size = 0.5, color = "gray30", linetype = "dashed") +
  facet_wrap(~scale) +
  theme_bw() +
  theme(aspect.ratio = 1) +
  scale_x_continuous("Year") +
  scale_y_continuous("Population \n(Linear Scale)", 
                     limits = c(100, 55000),
                     breaks = seq(0, 55000, 5000),
                     labels = scales::comma,
                     minor_breaks = c()) +
  ggtitle("Data set 1")

simulated_plot_log1 <- estimation_simulated_data %>%
  filter(dataset == "dataset1") %>%
  mutate(scale = "Log2") %>%
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  geom_line(aes(y = y0), size = 0.5, color = "gray30", linetype = "dashed") +
  facet_wrap(~scale) +
  theme_bw() +
  theme(aspect.ratio = 1) +
  scale_x_continuous("Year") +
  scale_y_continuous("Population \n(Log Scale)",
                     trans = "log2",
                     limits = c(100, 55000),
                     breaks = 2^seq(0,10000,1),
                     labels = scales::comma,
                     minor_breaks = c())

# dataset 2
simulated_plot_linear2 <- estimation_simulated_data %>%
  filter(dataset == "dataset2") %>%
  mutate(scale = "Linear") %>%
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  geom_line(aes(y = y0), size = 0.5, color = "gray30", linetype = "dashed") +
  facet_wrap(~scale) +
  theme_bw() +
  theme(aspect.ratio = 1) +
  scale_x_continuous("Year") +
  scale_y_continuous("Population \n(Linear Scale)", 
                     limits = c(100, 55000),
                     breaks = seq(0, 55000, 5000),
                     labels = scales::comma,
                     minor_breaks = c()) +
  ggtitle("Data set 2")

simulated_plot_log2 <- estimation_simulated_data %>%
  filter(dataset == "dataset2") %>%
  mutate(scale = "Log2") %>%
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  geom_line(aes(y = y0), size = 0.5, color = "gray30", linetype = "dashed") +
  facet_wrap(~scale) +
  theme_bw() +
  theme(aspect.ratio = 1) +
  scale_x_continuous("Year") +
  scale_y_continuous("Population \n(Log Scale)", 
                     trans = "log2",
                     limits = c(100, 55000),
                     breaks = 2^seq(0,10000,1),
                     labels = scales::comma,
                     minor_breaks = c())

(simulated_plot_linear1 + simulated_plot_log1) /
(simulated_plot_linear2 + simulated_plot_log2)
```

\cref{fig:estimation-simulated-data} display scatter plots of the two unique data sets on both the linear and logarithmic base two scales; a logarithm of base two was selected in order to aid in participants estimation of time until the population doubled in 'Intermediate Q3' \pcref{tab:estimation-questions-table}.
Participants were shown the graphic of both data sets on either the linear or logarithmic base two scale with labels adjusted to reflect the associated scenario context and scale.
Grid lines for the $y$-axis were set to be consistent for the same scale across both data sets with the linear scale increasing by 5,000 and the logarithmic base two scale doubling, thus demonstrating the additive and multiplicative contextual appearance and interpretation of each scale respectively.
Minor $y$-axis grid lines were removed to avoid participants anchoring to the midway point between grid lines; this is particularly important on the logarithmic scale since a halfway grid line spatially does not correspond to a halfway point numerically.
Grid lines for the $x$-axis spanned a range of 50 with major grid lines every ten units in time apart and minor grid lines indicating every five units in time.
The time unit labels on the $x$-axis reflected 0 to 50 ABY (After Battle of Yavin) for the Ewok scenario and were adjusted to 4500 to 4550 Stardates for the Tribble Scenario to align with the associated popular media depiction of each figure as well as disguise the use of the same underlying data simulation model and estimation questions across both scenarios.

## Results

Participant recruitment and study deployment was conducted via Prolific, a crowd sourcing website, on Wednesday, March 23, 2022 during which 302 individuals each completed all six estimation questions for each scenario (total of twelve questions per individual).
The data set used for analysis contained the unique participant identification and indicated the scenario, scale, data set, and estimation question along with the participant text response or quantitative estimate, calculation input and evaluation, and associated scratch work.
A total of 145 participants answered questions related to data set one on the linear scale and data set two on the logarithmic base two scale with 157 participants answering questions related to data set one on the logarithmic scale and data set two on the linear scale.
Sketches for each question are used to demonstrate the estimation tasks participants are asked to conduct.
An array of graphical displays allow for visual inspection of participant responses and provides suggestions about the implications of displaying exponentially increasing data on the logarithmic scale.

### Open Ended

Before participants were asked to estimate numeric quantities, they were asked to provide an open ended response and describe how the population changes over time. 
This required participants to spend time exploring the graphic and reflect upon how the data displayed relates to the contextual application.
The `tidytext` and `corpus` packages in R [@tidytext_pkg; @corpus_pkg] were used to extract and stem words from participant text responses; stop words such as 'the' and 'is' as well as numbers were removed from the cleaned word responses.
The `wordcloud` package [@wordcloud_pkg] was used to create a cloud comparing frequencies of words across the two scales \pcref{fig:estimation-word-cloud}. The comparison word cloud is generated by defining $p_{i,j}$ as the rate in which word $i$ occurs when describing the data on scale $j$ where $p_j$ is the average rate across the scales $\sum_i{\frac{p_{i,j}}{\text{N scales}}}$. 
The maximum deviation for each word is calculated by $max_i(p_{i,j} - p_j)$ and mapped to the size of the word with the position of the word determined by the scale in which the maximum occurs.

```{r, estimation-word-cloud, fig.cap = "Estimation word cloud", fig.height=6, fig.width=6, out.width = "75%", message=FALSE, warning=FALSE, echo = F}
set.seed(68505)
q0_text_summary %>%
  reshape2::acast(stem_word ~ scale, value.var = "count", fill = 0) %>%
  comparison.cloud(colors = c("steelblue", "orange2"),
                   max.words = 100,
                   rot.per = 0)
```

The comparison word cloud illustrates the general terminology participants used when describing the scatter plots shown on each scale.
Participants more frequently referred to terms such as 'exponential' and 'rapid' when shown the scatter plot on the linear scale while 'double' and 'quadruple' were often used to describe the graphic when shown on the logarithmic scale; indicating participants read the $y$-axis labels and noticed the doubling grid lines.
The use of the term 'linear' when participants are describing the appearance of the data displayed on the logarithmic scale suggests that a portion of participants did not recognize the data was exponentially increasing rather than linearly increasing due to the change in the visual appearance of the data between the two scales.

### Elementary Q1: Estimation of population

In order to examine the effect of scale on literal reading of the data, participants were asked to estimate the population in year 10 \pcref{fig:qe1-sketch}.
The true estimated population in year 10 based on the underlying parameter estimates is 481.61 with simulated points of 445.48 and 466.9 for data sets one and two respectively.
The median participant estimate across both scales and data sets was 500 with innerquartile ranges of 500 and 400 for data set one and data set two respectively when displayed on the linear scale and 48 and 12 for data set one and data set two respectively when displayed on the logarithmic scale.

```{r qe1-sketch, eval = T, fig.height = 8, fig.width = 8, out.width = "100%", fig.cap = "Elementary Q1 Sketch"}
knitr::include_graphics("images/03-estimation/qe1-sketch.png")
```

Density plots are used to illustrate the distribution of the quantitative estimates provided by participants.
\pcref{fig:qe1-density-plot-10-all} reveals a larger variance in quantitative population estimates made on the linear scale compared to the logarithmic scale.
There is strong support that participants were anchoring to grid lines and base ten values as highlighted by the high density of estimates at 512 and 500 on the log scale as well as local maximums near multiples of ten such as 500 and 1000.

```{r, eq1-data, message=FALSE, warning=FALSE}
qe1_data <- estimation_model_data %>% 
  filter(q_id == "QE1") %>%
  mutate(response = as.numeric(response)) %>%
  mutate(showed_work_cutoff = ifelse(showed_work_n >= 2, "yes", "no"))
```

```{r qe1-info, eval = F}
estimation_simulated_data %>% 
  filter(x == 10) %>%
  knitr::kable(digits = 2)

qe1_data %>%
  group_by(dataset, scale) %>%
  get_summary_stats(response, type = "median_iqr") %>%
  knitr::kable(digits = 2)
```

```{r, qe1-density-plot-10-all, fig.cap = "Elementary Q1 Density in year 10", fig.width = 9, fig.height = 9, out.width = "100%", message=FALSE, warning=FALSE}
qe1_density10_1 <- densityPlot(data = qe1_data, datasetID = "dataset1", "response", xlabel = "Estimated Population at 10", x_limits = c(0,1200), zoom = F) +
  geom_text(aes(label = "512", y = Inf, x = 512), color = "orange3", size = 3, hjust = -0.25, vjust = 2, show.legend = F) +
  ggtitle("Data set 1")

qe1_density10_2 <- densityPlot(data = qe1_data, datasetID = "dataset2", "response", xlabel = "Estimated Population at 10", x_limits = c(0,1200), zoom = F) +
  geom_text(aes(label = "512", y = Inf, x = 512), color = "orange3", size = 3, hjust = -0.25, vjust = 2, show.legend = F) +
  ggtitle("Data set 2")

qe1_density10_1 / qe1_density10_2
```

During the study, participants were explicitly asked to estimate the population during year 10; this value corresponds to a low magnitude where the population is condensed in a small region on the linear scale as opposed to later in time when larger magnitudes in population can be seen.
While the results provided support for less variability in the estimated population in year 10 on the logarithmic scale, it is important to evaluate the accuracy of estimates along the domain.
In two estimation questions related to intermediate level reading between the data, participants are asked to provide an increase and change in population between years 20 and 40, thus requiring participants to make first level estimates at these locations \pcref{fig:qi1-sketch; fig:qi2-sketch}.
In order to understand the effect of the location along the domain, I extracted first level estimates for years 20 and 40 from participant calculations and scratch-work.
I first compared population estimates from the explicitly asked year 10 location between participants who used the calculator and scratchpad in two or more of the questions to determine whether the there were differences or biases between those who used resources for estimation compared to those who did not utilize the resources [Appendix 3b](#estimation-comparison).
About half of the participants fell into the category which provided scratch work and half did not. 

The true population from the underlying parameters in year 20 is 1483.01 with closest simulated point values of 1529.19 and 1288.9 for data sets one and two respectively; this location still results in a relatively low magnitude of population, but is closer to the crux of the exponential curve. 
In year 40, the true population from the underlying parameters in year 40 is 15846.35 with closest simulated point values of 17046.94 and 24186.34 for data sets one and two respectively. 
It is important to note the discrepancy in simulated point values in year 40 between the two data sets as a result to a multiplicative error causing a larger variance in simulated points for later years and larger magnitudes.

```{r estimation-spaghetti-plots}
spaghettiPlotsTogether <- function(yearVals, scale, datasetID){
  
  plot <- population_estimates_data %>%
    filter(population_est < 55000, year %in% yearVals, dataset %in% datasetID) %>%
  ggplot() +
    
    # add spaghetti segments
    geom_segment(aes(x = yearest_true, y = population_est, xend = 0, yend = population_est, color = scale), alpha = 0.3) +
    geom_segment(aes(x = yearest_true, y = 100, xend = yearest_true, yend = population_est, color = scale), alpha = 0.3) +
    
    
    # add arrows for true value and closest point value
    geom_segment(aes(x = year, y = true_value, xend = -Inf  + 5, yend = true_value), size = 0.5, alpha = 0.9, linetype = "solid", color = "black", arrow = arrow(length=unit(0.1,"cm"), ends="last", type = "closed")) +
    geom_segment(aes(x = year, y = closest_pt_value, xend = -Inf + 5, yend = closest_pt_value), size = 0.5, alpha = 0.9, linetype = "solid", color = "black", arrow = arrow(length=unit(0.1,"cm"), ends="last", type = "closed")) +
    geom_segment(aes(x = year, y = 100, xend = year, yend = true_value), size = 0.5, alpha = 0.9, linetype = "solid", color = "black", arrow = arrow(length=unit(0.1,"cm"), ends="last", type = "closed")) +
    geom_segment(aes(x = year, y = 100, xend = year, yend = closest_pt_value), size = 0.5, alpha = 0.9, linetype = "solid", color = "black", arrow = arrow(length=unit(0.1,"cm"), ends="last", type = "closed")) +
    
    # add points
    geom_point(data = estimation_simulated_data %>% filter(dataset %in% datasetID), aes(x = x, y = y), alpha = 0.7, shape = 1, size = 1) +
    
    # extra
    facet_grid(~year, labeller = label_both) +
    theme_bw() +
    theme(aspect.ratio = 1) +
    scale_color_manual(values = c("steelblue", "orange3"), guide = guide_legend(override.aes = list(alpha = 1))) +
    scale_fill_manual(values = c("steelblue", "orange3")) +
    xlab("Year")
  
  if(scale == "linear"){
    plot <- plot +
      scale_y_continuous("Population", 
                         limits = c(100, 55000),
                       breaks = seq(0, 55000, 5000),
                       labels = scales::comma,
                       minor_breaks = c())
  } 
  
  if(scale == "log2"){
    plot <- plot +
    scale_y_continuous("Population \n (log2)", 
                       trans = "log2",
                       limits = c(100, 55000),
                       breaks = 2^seq(0,10000,1),
                       labels = scales::comma,
                       minor_breaks = c()
                       )
  }

plot
}
```

```{r spaghetti-dataset1, message=FALSE, warning=FALSE, fig.cap = "Estimated Population: Data set 1", fig.width = 9, fig.height = 6, out.width = "100%"}
p1 <- spaghettiPlotsTogether(yearVals = c(10,20,40), scale = "linear", datasetID = "dataset1") + ggtitle("Data set 1")
p2 <- spaghettiPlotsTogether(yearVals = c(10,20,40), scale = "log2", datasetID = "dataset1")
p1/p2
```

```{r spaghetti-dataset2, message=FALSE, warning=FALSE, fig.cap = "Estimated Population: Data set 2", fig.width = 9, fig.height = 6, out.width = "100%"}
p3 <- spaghettiPlotsTogether(yearVals = c(10,20,40), scale = "linear", datasetID = "dataset2") + ggtitle("Data set 2")
p4 <- spaghettiPlotsTogether(yearVals = c(10,20,40), scale = "log2", datasetID = "dataset2")
p3/p4
```

Population estimates for year 10 from participants who used the scratchpad and first level estimates for years 20 and 40 are shown with spaghetti plots in \cref{fig:spaghetti-dataset1} and \cref{fig:spaghetti-dataset2} displayed on both the linear and logarithmic base two scale.
The scale in which the estimate was made is indicated blue for linear and orange for log with the segments mapped from the participant estimated population to the true year based on the underlying data equation.
As the domain increases, we observe an increased accuracy in estimates made on the linear scale while estimates made on the logarithmic scale remain accurate throughout. 
Previously noted, the simulated point corresponding to year 40 in data set 2 has a large deviation from the true underlying data equation; \cref{fig:spaghetti-dataset2} highlights that some participants were reading the data points as opposed to first detecting the underlying trend and making estimates based on the identified trend.
This provides argument that estimates are highly subjective to the particular data set.

In extracting participant first level estimates from their calculation and scratch work, I observed participants were resistant to estimating between grid lines and had a greater tendency to anchor their estimates to the grid line estimates on the logarithmic scale.
\cref{fig:common-population-estimates} illustrates the number of participants who provided that estimate on either the linear or logarithmic base two scale. 
True values based on underlying estimates, closest simulated point values, and grid line breaks are indicated by the horizontal line types.
In particular, for year 40 in data set 1, the closest point (17046.94) falls close to the logarithmic grid line (16384); participants greatly anchored to the grid line of 16384 with some participants adjusting to 16500 or 17000, anchoring again to a base ten value.
In a similar situation, for year 40 in data set 2, the closest point (24186.34) falls close to the linear grid line (25000); more participants adjusted their estimates to 24500 or 24000 rather than anchoring to the grid line.
This suggests that participants were more likely to provide estimates which deviated from grid lines when making estimates on the linear scale, indicating they are more comfortable with interpreting values on a linear scale as opposed to the logarithmic scale.

```{r qe1-first-level-info, eval=FALSE, message=FALSE, warning=FALSE}
qe1_data %>%
  group_by(dataset, scale, showed_work_cutoff) %>%
  get_summary_stats(response, type = "median_iqr") %>%
  knitr::kable(digits = 2)

estimation_simulated_data %>% 
  filter(x == 20) %>%
  knitr::kable(digits = 2)

estimation_simulated_data %>% 
  filter(x == 40) %>%
  knitr::kable(digits = 2)
```

```{r message=FALSE, warning=FALSE}
qe1_popest_common_responses <- population_estimates_data %>%
  group_by(scale, year, dataset, true_value, closest_pt_value, population_est) %>%
  dplyr::summarize(count = n()) %>%
  filter(count > 3) %>%
  arrange(year, scale, -count)

actual_values_data <- qe1_popest_common_responses %>%
  # filter(scale == "linear", "log") %>%
  select(year, scale, dataset, true_value, closest_pt_value) %>%
  unique() %>%
  pivot_wider(id_cols = c("year", "scale", "true_value"),
              names_from = "dataset",
              values_from = "closest_pt_value") %>%
  pivot_longer(cols = c("true_value", "dataset2", "dataset1"),
              names_to = "dataset",
              values_to = "population_est") %>%
  mutate(dataset = ifelse(dataset == "true_value" & scale == "linear", "dataset1",
                          ifelse(dataset == "true_value" & scale == "log2", "dataset2", dataset))) %>%
  mutate(scale = "linear", 
         true_value = NA,
         closest_pt_value = NA,
         count = NA) %>%
  unique() %>%
  select(year, scale, dataset, true_value, closest_pt_value, population_est, count)

qe1_popest_common_responses  <- qe1_popest_common_responses  %>%
  rbind(actual_values_data)
response_order <- c(unique(round(qe1_popest_common_responses$population_est,2))) %>% sort()

popEstCommonPlot <- function(yearVal, datasetID){
  
  common_plot <- qe1_popest_common_responses %>%
    filter(year %in% yearVal, dataset == datasetID) %>%
    mutate(population_est = round(population_est, 2)) %>%
    mutate(population_est = factor(population_est, response_order)) %>%
    mutate(population_est = factor(population_est, levels = response_order)) %>%
    ggplot(aes(x = count, xmin = 0, xmax = count, y = population_est, color = scale, shape = scale)) +
    geom_linerange(position = position_dodge(.5), show.legend = F) +
    geom_point(position = position_dodge(0.5) ) +
    geom_hline(aes(yintercept = as.factor(round(true_value,2)), linetype = "a")) +
    geom_hline(aes(yintercept = as.factor(round(closest_pt_value,2)), linetype = "b")) +
    geom_hline(data = grid_lines_data, aes(yintercept = as.factor(round(grid_lines, 2)), color = scale, linetype = "c")) +
    facet_wrap(~ year, ncol = 3, scales = "free_y", labeller = label_both) +
    theme_test() +
    theme(aspect.ratio = 0.75) +
    scale_shape_manual("Scale", values = c(16,15)) +
    scale_color_manual("Scale", values = c("steelblue", "orange3")) +
    scale_linetype_manual("", labels = c("True value", "Closest point", "Grid line"), values = c("solid", "dashed", "dotted")) +
    scale_y_discrete("Estimated Population") +
    scale_x_continuous("Number of participants")
  common_plot
}
```

```{r fig.height = 4, fig.width=9, message=FALSE, warning=FALSE, common-population-estimates, fig.cap="Estimated Population: Common responses", out.width="100%"}
p5 <- popEstCommonPlot(yearVal = c(40), datasetID = "dataset1") +
  ggtitle("Data set 1")

p6 <- popEstCommonPlot(yearVal = c(40), datasetID = "dataset2") +
  ggtitle("Data set 2")

p5 + p6
```

### Elementary Q2: Estimation of time

In addition to estimating the population from a given year, participants were asked to estimate the year in which the population reaches 4000 \pcref{fig:qe2-sketch}.
This requires literal reading of the data by mapping a value given on the $y$-axis to its corresponding value on the $x$-axis. 
The true estimated year  in year 10 based on the underlying parameter estimates is 481.61 with simulated points of 445.48 and 466.9 for data sets one and two respectively.
The median participant estimate across both scales and data sets was 500 with innerquartile ranges of 500 and 400 for data set one and data set two respectively when displayed on the linear scale and 48 and 12 for data set one and data set two respectively when displayed on the logarithmic scale.

```{r qe2-sketch, eval = T, fig.height = 4, fig.width = 6, out.width = "100%", fig.cap = "Elementary Q2 Sketch"}
knitr::include_graphics("images/03-estimation/qe2-sketch.png")
```

+ About the same accuracy on both scales, maybe a slight tendency to overestimate (maybe due to estimating the "visual trend" estimate on the log scale as indicated by data set 1?).
+ Not sure there is enough evidence to claim participants were more accurate on the linear scale, but would like to do more studies focusing on participants ability to read between the y-axis tick marks on the logarithmic scale. They could also be anchoring to the tick mark of 4096.
+ but... based on the density plots above, on the log scale, participants might have a tendency to be fitting a visual trend first and then estimating as indicated by the overestimation on the log scale for data set 1.

```{r, eq2-data, message=FALSE, warning=FALSE}
qe2_data <- estimation_model_data %>% 
  filter(q_id == "QE2") %>%
  mutate(response = as.numeric(response))
```

```{r qe2-info, eval = F}
estimation_simulated_data %>% 
  filter(abs(y - 4000) < 1500) %>%
  arrange(dataset, y)

qe2_data %>%
  group_by(dataset, scale) %>%
  get_summary_stats(response, type = "median_iqr")
```

```{r, qe2-density-plot, fig.cap = "Elementary Q2 Density", fig.width = 9, fig.height = 9, out.width = "100%", message=FALSE, warning=FALSE}
qe2_density_1 <- densityPlot(data = qe2_data, datasetID = "dataset1", "response", xlabel = "Estimated Year", x_limits = c(0,50), zoom = F, gridlines = F) +
  ggtitle("Data set 1")

qe2_density_2 <- densityPlot(data = qe2_data, datasetID = "dataset2", "response", xlabel = "Estimated Population at 10", x_limits = c(0,50), zoom = F, gridlines = F) +
  ggtitle("Data set 2")

qe2_density_1 / qe2_density_2

```

### Intermediate Q1: Additive increase in population

```{r qi1-sketch, eval = T, fig.height = 8, fig.width = 8, out.width = "100%", fig.cap = "Intermediate Q1 Sketch"}
knitr::include_graphics("images/03-estimation/qi1-sketch.png")
```


### Intermediate Q2: Multiplicative change in population

```{r qi2-sketch, eval = T, fig.height = 8, fig.width = 8, out.width = "100%", fig.cap = "Intermediate Q2 Sketch"}
knitr::include_graphics("images/03-estimation/qi2-sketch.png")
```


### Intermediate Q3: Time until population doubles

```{r qi3-sketch, eval = T, fig.height = 8, fig.width = 8, out.width = "100%", fig.cap = "Intermediate Q3 Sketch"}
knitr::include_graphics("images/03-estimation/qi3-sketch.png")
```

## Discussion and Conclusion

+ Understanding logarithmic logic is difficult
  + Misunderstanding in QI1 and QI2
+ Anchoring, anchoring, anchoring!
  + On the log2 scale, but on base 10 is still strong
+ Participants were reading the data points rather than the trends, with a few exceptions
+ Log vs Linear Scale
  + linear scale ad greater variability in general (not always)
  + Log scale was occasionally more accurate (depends on magnitude and location of point in relation to the grid lines)
  + Depended on the values being asked.
  + Participants more likely to estimate between grid lines on the linear scale
